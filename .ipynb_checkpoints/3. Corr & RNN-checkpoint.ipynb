{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2bb655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:54.928521Z",
     "start_time": "2023-04-23T15:02:09.669768Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "path = './Data/Pickle Files/Processed_Dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32870f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:56.377289Z",
     "start_time": "2023-04-23T15:02:56.359286Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca017c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:57.335373Z",
     "start_time": "2023-04-23T15:02:57.062883Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(path+'features.pickle', 'rb') as f:\n",
    "#     feature_df = pickle.load(f)\n",
    "\n",
    "feature_df = pd.read_pickle(path+'features.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea9df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:57.993235Z",
     "start_time": "2023-04-23T15:02:57.919948Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(path+'disease_Proc_df.pickle', 'rb') as f:\n",
    "#     disease_df = pickle.load(f)\n",
    "    \n",
    "disease_df = pd.read_pickle(path+'disease_Proc_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea8fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:58.621126Z",
     "start_time": "2023-04-23T15:02:58.499125Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e7998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:59.216076Z",
     "start_time": "2023-04-23T15:02:59.184029Z"
    }
   },
   "outputs": [],
   "source": [
    "disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04031108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:02:59.826867Z",
     "start_time": "2023-04-23T15:02:59.807863Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(feature_df, disease_df, on=['Year', 'State'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6b6c1",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d91f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        corr, p_value = pearsonr(corr_matrix.iloc[:, i], corr_matrix.iloc[:, j])\n",
    "        if p_value < alpha and corr_matrix.columns[i].startswith('CAN5_1'):\n",
    "            print(f\"Correlation between {corr_matrix.columns[i]} and {corr_matrix.columns[j]} is significant (p-value: {p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454f3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f24e51",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a74d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:03.602550Z",
     "start_time": "2023-04-23T15:03:03.583549Z"
    }
   },
   "outputs": [],
   "source": [
    "state_list = df['State'].unique()\n",
    "seq_length = 2\n",
    "seq_length_plus_diff = seq_length+1\n",
    "\n",
    "df = df.drop(['StateDesc'], axis=1)\n",
    "df = df.sort_values(by='Year')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98314c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:04.251587Z",
     "start_time": "2023-04-23T15:03:04.240581Z"
    }
   },
   "outputs": [],
   "source": [
    "min_year_val = 2016\n",
    "min_year_test = 2019\n",
    "\n",
    "train_data = df[df['Year'] < min_year_val].copy()\n",
    "val_data = df[(df['Year'] >= min_year_val-seq_length_plus_diff) & (df['Year'] < min_year_test)].copy()\n",
    "test_data = df[df['Year'] >= min_year_test-seq_length_plus_diff].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841eecf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:04.844340Z",
     "start_time": "2023-04-23T15:03:04.832338Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data_compare_acc = val_data[(val_data['Year'] >= min_year_val) & (val_data['Year'] < min_year_test) ]\n",
    "test_data_compare_acc = test_data[test_data['Year'] >= min_year_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb674402",
   "metadata": {},
   "source": [
    "# Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fe63a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:05.962943Z",
     "start_time": "2023-04-23T15:03:05.951942Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_diff(df):\n",
    "    \n",
    "    Base_Year = np.min(df['Year'])\n",
    "    \n",
    "    Base_row = df[df['Year'] == Base_Year]\n",
    "    \n",
    "    df_diff = pd.DataFrame()\n",
    "\n",
    "    for state in state_list:\n",
    "\n",
    "        df_state = df[df['State'] == state]\n",
    "        df_state_diff = df_state.iloc[:,2:].diff().dropna()\n",
    "        df_state = pd.concat([df_state[['Year', 'State']] , df_state_diff ], axis=1)\n",
    "        df_state.dropna(inplace=True)\n",
    "\n",
    "        df_diff = pd.concat([df_diff, df_state], axis=0)\n",
    "    \n",
    "    df['Year'] = df['Year'] + 1\n",
    "    base_df = df \n",
    "    df = df_diff\n",
    "    \n",
    "    return base_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f8b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:07.097177Z",
     "start_time": "2023-04-23T15:03:06.546638Z"
    }
   },
   "outputs": [],
   "source": [
    "base_df_train, train_data = df_diff(train_data)\n",
    "base_df_val,val_data = df_diff(val_data)\n",
    "base_df_test,test_data = df_diff(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8571309",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d254ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:07.835209Z",
     "start_time": "2023-04-23T15:03:07.815208Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_val = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_test = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f5882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T15:03:08.762542Z",
     "start_time": "2023-04-23T15:03:08.391254Z"
    }
   },
   "outputs": [],
   "source": [
    "#columns_to_normalize = list(df.columns[2:-8])\n",
    "\n",
    "# To standardize the target columns as well\n",
    "\n",
    "columns_to_normalize = list(df.columns[2:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data[columns_to_normalize] = scaler_train.fit_transform(train_data[columns_to_normalize])\n",
    "\n",
    "val_data[columns_to_normalize] = scaler_val.fit_transform(val_data[columns_to_normalize])\n",
    "\n",
    "test_data[columns_to_normalize] = scaler_test.fit_transform(test_data[columns_to_normalize])\n",
    "\n",
    "\n",
    "df_cols = list(df.columns)\n",
    "input_cols = [c for c in df_cols if c not in ['Year','State','StateDesc','CAN10_1','CAN11_1','CAN5_1','CAN6_1','CAN7_1','CAN8_1','CAN9_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290affbc",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6fa603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T22:43:13.890376Z",
     "start_time": "2023-04-23T22:43:13.879743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f795a45",
   "metadata": {},
   "source": [
    "For adding the features from previous Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be3975b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:51:15.160230Z",
     "start_time": "2023-04-23T14:51:15.136229Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length,target_col):\n",
    "    \n",
    "    df_cols = list(df.columns)\n",
    "    \n",
    "    output_cols = [target_col]\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data.loc[i-seq_length:i, input_cols].values)\n",
    "        y.append(data.loc[i, output_cols])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X = X.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    X = tf.convert_to_tensor(X)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    \n",
    "\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349892d4",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba30520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:51:16.957703Z",
     "start_time": "2023-04-23T14:51:16.944708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that creates the LSTM model\n",
    "\n",
    "def create_model(num_layers, num_nodes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_nodes, input_shape=input_shape, activation='relu'))\n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dense(num_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d88f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:30:33.282103Z",
     "start_time": "2023-04-23T13:30:33.266092Z"
    }
   },
   "outputs": [],
   "source": [
    "# Takes about 20 minutes\n",
    "# Test with one state and one type of cancer\n",
    "\n",
    "# state = 'WY'\n",
    "# target_col = 'CAN10_1'\n",
    "# state_train_df = train_data[train_data['State'] == state]\n",
    "# state_train_df = state_train_df.sort_values(by='Year')\n",
    "# state_train_df = state_train_df.reset_index(drop=True)\n",
    "\n",
    "# state_val_df = val_data[val_data['State'] == state]\n",
    "# state_val_df = state_val_df.sort_values(by='Year')\n",
    "# state_val_df = state_val_df.reset_index(drop=True)\n",
    "\n",
    "# state_test_df = test_data[test_data['State'] == state]\n",
    "# state_test_df = state_test_df.sort_values(by='Year')\n",
    "# state_test_df = state_test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, y_train = create_sequences(state_train_df, seq_length,target_col)\n",
    "# X_val, y_val = create_sequences(state_val_df, seq_length,target_col)\n",
    "# X_test, y_test = create_sequences(state_test_df, seq_length,target_col)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Define the hyperparameters to tune\n",
    "# param_grid = {\n",
    "#     'num_layers': np.array([1, 2, 3]),\n",
    "#     'num_nodes': np.array([32, 64, 128]),\n",
    "#     'epochs': np.array([50, 100, 200]),\n",
    "#     'batch_size': np.array([1, 16, 32])\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Create the KerasRegressor object\n",
    "# regressor = KerasRegressor(build_fn=create_model, input_shape=input_shape)\n",
    "\n",
    "\n",
    "# X_train_numpy = X_train.numpy()\n",
    "# y_train_numpy = y_train.numpy()\n",
    "# X_val_numpy = X_val.numpy()\n",
    "# y_val_numpy = y_val.numpy()\n",
    "# X_test_numpy = X_test.numpy()\n",
    "# y_test_numpy = y_test.numpy()\n",
    "\n",
    "# # Use GridSearchCV to perform the grid search\n",
    "# tscv = TimeSeriesSplit(n_splits=3)\n",
    "# grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=tscv)\n",
    "# grid_search.fit(X_train_numpy, y_train_numpy, validation_data=(X_val_numpy, y_val_numpy),verbose=0)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"MSE: \", abs(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07c96a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:51:34.276299Z",
     "start_time": "2023-04-23T14:51:30.528493Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the LSTM model with the best hyperparameters\n",
    "\n",
    "# best_num_layers = grid_search.best_params_['num_layers']\n",
    "# best_num_nodes = grid_search.best_params_['num_nodes']\n",
    "# best_epochs = grid_search.best_params_['epochs']\n",
    "# best_batch_size = grid_search.best_params_['batch_size']\n",
    "\n",
    "best_num_layers = 1\n",
    "best_num_nodes = 32\n",
    "best_epochs = 100\n",
    "best_batch_size = 32\n",
    "\n",
    "num_features = len(input_cols)\n",
    "input_shape = (seq_length+1, num_features)\n",
    "\n",
    "\n",
    "final_model = create_model(num_layers=best_num_layers, num_nodes=best_num_nodes, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345ca8a",
   "metadata": {},
   "source": [
    "Design the best model based on parameter tuning.\n",
    "\n",
    "For each state and cancer type, fit the model and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21b76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:37:56.567417Z",
     "start_time": "2023-04-23T13:37:56.563116Z"
    }
   },
   "outputs": [],
   "source": [
    "target_cols = ['CAN10_1','CAN11_1','CAN5_1','CAN6_1','CAN7_1','CAN8_1','CAN9_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed48b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T13:40:29.213213Z",
     "start_time": "2023-04-23T13:38:02.874690Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "\n",
    "for state in state_list:\n",
    "    # Subset the data for the current state\n",
    "\n",
    "    for target_col in target_cols:\n",
    "        state_preds = {}\n",
    "        \n",
    "        state_train_df = train_data[train_data['State'] == state]\n",
    "        state_train_df = state_train_df.sort_values(by='Year')\n",
    "        state_train_df = state_train_df.reset_index(drop=True)\n",
    "\n",
    "        state_val_df = val_data[val_data['State'] == state]\n",
    "        state_val_df = state_val_df.sort_values(by='Year')\n",
    "        state_val_df = state_val_df.reset_index(drop=True)\n",
    "\n",
    "        state_test_df = test_data[test_data['State'] == state]\n",
    "        state_test_df = state_test_df.sort_values(by='Year')\n",
    "        state_test_df = state_test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        X_train, y_train = create_sequences(state_train_df, seq_length,target_col)\n",
    "        X_val, y_val = create_sequences(state_val_df, seq_length,target_col)\n",
    "        X_test, y_test = create_sequences(state_test_df, seq_length,target_col)\n",
    "        \n",
    "        \n",
    "        X_train_numpy = X_train.numpy()\n",
    "        y_train_numpy = y_train.numpy()\n",
    "        X_val_numpy = X_val.numpy()\n",
    "        y_val_numpy = y_val.numpy()\n",
    "        X_test_numpy = X_test.numpy()\n",
    "        y_test_numpy = y_test.numpy()\n",
    "\n",
    "\n",
    "        # Train the final model on the entire training dataset\n",
    "        final_model.fit(X_train_numpy, y_train_numpy, epochs = best_epochs, batch_size=best_batch_size, verbose=0)\n",
    "        \n",
    "#         y_pred = final_model.predict(X_val_numpy)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "#         # Create a dict for creating overview_df with results\n",
    "#         state_preds['State'] = state\n",
    "#         state_preds['Target'] = target_col\n",
    "#         state_preds['Year'] = [min(state_val_df['Year']) + i + seq_length for i in range(len(y_val_numpy))]\n",
    "#         state_preds['Predicted_value'] = pd.Series(y_pred.reshape(-1).tolist())\n",
    "#         state_preds['Actual_value'] = pd.Series(y_val_numpy.reshape(-1).tolist())\n",
    "#         state_preds['Accuracy'] = pd.Series([mean_squared_error([y_val_numpy[i]], [y_pred[i]]) for i in range(len(y_val_numpy))])\n",
    "#         preds_list.append(state_preds)\n",
    "\n",
    "\n",
    "# # Create a df to show results\n",
    "# overview_df = pd.DataFrame(preds_list).explode(['Year','Predicted_value', 'Actual_value', 'Accuracy'])\n",
    "# overview_df = overview_df.reset_index(drop=True)\n",
    "\n",
    "# # # Save overview_df\n",
    "# # with open('./Data/Pickle Files/overview_df.pickle', 'wb') as f:\n",
    "# #     pickle.dump(overview_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # pivot overview df to be used in our prediction df\n",
    "# pivot_df = pd.pivot_table(overview_df, values='Predicted_value', index=['State', 'Year'], columns=['Target'])\n",
    "# pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# # create prediction df\n",
    "# pred_val_df = pd.merge(val_data.iloc[:, :-7], pivot_df, on=['Year', 'State'])\n",
    "\n",
    "# # Save pred_val_df\n",
    "# with open(path + 'pred_val_df.pickle', 'wb') as f:\n",
    "#     pickle.dump(pred_val_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b096882a",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88aa7e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:13:10.334120Z",
     "start_time": "2023-04-23T14:13:10.203151Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.DeepExplainer(final_model, X_train_numpy)\n",
    "shap_values = explainer.shap_values(X_val_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2f67d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-23T14:01:30.009248Z",
     "start_time": "2023-04-23T14:01:29.618394Z"
    }
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(final_model,X_train_numpy)\n",
    "shap_values = explainer.shap_values(X_val_numpy.reshape(-1, num_features),nsamples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d7280",
   "metadata": {},
   "source": [
    "## Inverse Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1705c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:22.782125Z",
     "start_time": "2023-04-18T20:16:22.427492Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(path+'pred_val_df.pickle', 'rb') as f:\n",
    "#     pred_val_df = pickle.load(f)\n",
    "\n",
    "pred_val_df = pd.read_pickle(path+'pred_val_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8cfb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:23.357637Z",
     "start_time": "2023-04-18T20:16:23.316477Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_val_df[columns_to_normalize] = scaler_val.inverse_transform(pred_val_df[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ed632",
   "metadata": {},
   "source": [
    "# Inverse Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56883eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:24.788067Z",
     "start_time": "2023-04-18T20:16:24.626740Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_df_val_filtered = base_df_val[(base_df_val['Year'] >= np.min(base_df_val['Year'] ) + seq_length) & (base_df_val['Year']< np.max(base_df_val['Year'] ) )].sort_values(by=['State','Year'])\n",
    "base_df_val_filtered = base_df_val_filtered.reset_index(drop=True)\n",
    "\n",
    "pred_val_df = pred_val_df.sort_values(by=['State','Year'])\n",
    "pred_val_df = pred_val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042b271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:25.366200Z",
     "start_time": "2023-04-18T20:16:25.351090Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_val_df_inv_diff = base_df_val_filtered.iloc[:,2:].add(pred_val_df.iloc[:,2:])\n",
    "pred_val_df = pd.concat([pred_val_df[['Year', 'State']] , pred_val_df_inv_diff ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b84dd3",
   "metadata": {},
   "source": [
    "Compare pred_val_df with val_data_compare_acc (2016-2018) and create a dataset with columns: State, Cancer Type, MSE\n",
    "Then get the dataset from Baseline and compare MSE s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9871087",
   "metadata": {},
   "source": [
    "### Comparison with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33955a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:28.139269Z",
     "start_time": "2023-04-18T20:16:28.026615Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('./Data/Pickle Files/overview_df.pickle', 'rb') as f:\n",
    "#     overview_df = pickle.load(f)\n",
    "\n",
    "overview_df = pd.read_pickle('./Data/Pickle Files/overview_df.pickle')\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c139927f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:29.613324Z",
     "start_time": "2023-04-18T20:16:29.569589Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overview_df = overview_df.loc[:, ['State', 'Target', 'Year', 'Accuracy']][((overview_df['State'] == 'CA') | (overview_df['State'] == 'NY') | (overview_df['State'] == 'TX'))]\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7384e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:31.184916Z",
     "start_time": "2023-04-18T20:16:30.804873Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_df = pd.read_csv('./Data/Pickle Files/BasisModelAcc.csv')\n",
    "baseline_df = baseline_df.rename(columns={'Cancer':'Target'})\n",
    "baseline_df['State'] = baseline_df['State'].replace({'CAL':'CA', 'TEX':'TX'})\n",
    "baseline_df = baseline_df[['State', 'Target', 'Year', 'Accuracy']]\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da7f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:16:34.262848Z",
     "start_time": "2023-04-18T20:16:34.137962Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge the dataframes on 'State', 'Target', and 'Year'\n",
    "merged_df = pd.merge(overview_df, baseline_df, on=['State', 'Target', 'Year'], suffixes=('_pred', '_base'))\n",
    "\n",
    "# compute the difference in accuracy\n",
    "merged_df['Accuracy_diff'] = merged_df['Accuracy_pred'] - merged_df['Accuracy_base']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b922b2",
   "metadata": {},
   "source": [
    "## Forecasting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9510ed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-18T20:36:50.880602Z",
     "start_time": "2023-04-18T20:27:04.052743Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "train_fc_features = df[df['Year'] < min_year_test].copy()\n",
    "row_list = []\n",
    "\n",
    "for state in state_list:\n",
    "    row_dict = {}\n",
    "    # Subset the data for the current state\n",
    "    state_train_df = train_fc_features[train_fc_features['State'] == state]\n",
    "    state_train_df = state_train_df.sort_values(by='Year')\n",
    "    state_train_df = state_train_df.reset_index(drop=True)\n",
    "    state_train_df = state_train_df.dropna()\n",
    "    \n",
    "    row_dict['State'] = state\n",
    "    row_dict['Year'] = np.arange(2019, 2026)\n",
    "\n",
    "    for col in train_fc_features.columns[2:-7]:\n",
    "        # Fit an ARIMA model using the auto_arima function\n",
    "        model = auto_arima(state_train_df[col].dropna(), seasonal=False, suppress_warnings=True, error_action=\"ignore\")\n",
    "        print(f'Column: {col}, ARIMA Model: {model.order}')\n",
    "        forecast = model.predict(n_periods=7)\n",
    "        \n",
    "        row_dict[col] = list(forecast)\n",
    "    \n",
    "    row_list.append(row_dict)\n",
    "\n",
    "# pred_fc_features_df = pd.DataFrame(row_list).explode([x for x in list(train_fc_features.columns[:-7]) if x != 'State'])\n",
    "# pred_fc_features_df = pred_fc_features_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3ea8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:56:09.499326Z",
     "start_time": "2023-04-17T16:56:09.479328Z"
    }
   },
   "outputs": [],
   "source": [
    "state_train_df['NHAAC_MALE']\n",
    "HNAC_FEMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82130290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T16:17:44.421656Z",
     "start_time": "2023-04-17T16:17:44.010026Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pred_fc_features_df = pd.DataFrame(row_list).explode([x for x in list(train_fc_features.columns[:-7]) if x!= 'State'])\n",
    "pred_fc_features_df = pred_fc_features_df.reset_index(drop=True)\n",
    "pred_fc_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49fa93",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- Make the prediction for each of the states and cancers for the test dataset (Not validation) to report the accuracy for the data which haven't been seen \n",
    "\n",
    "- Compare the results with baseline model (ARIMA)\n",
    "\n",
    "- Predict the future data which we don't have any features for. This probably needs to predict the features like air pollution and demopraghic data for the future.\n",
    "\n",
    "- Use SHAP to find the features which have the most impact in each state, for each cancer (find the interesting things like if for most of the states and cancers the important features are the same or for instance, for some of them, some features are more important)\n",
    "\n",
    "- Have a map of the states in danger (By having a cut-off for 3 situations like Green, Yellow, Red)\n",
    "- Text Analysis on News\n",
    "- EDA on features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
