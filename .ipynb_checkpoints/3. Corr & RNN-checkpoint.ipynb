{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2bb655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:40:58.922361Z",
     "start_time": "2023-04-17T12:40:56.976804Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "path = './Data/Pickle Files/Processed_Dataframes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32870f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:40:59.961943Z",
     "start_time": "2023-04-17T12:40:59.946257Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72ca017c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:00.496927Z",
     "start_time": "2023-04-17T12:41:00.486927Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path+'features.pickle', 'rb') as f:\n",
    "    feature_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ea9df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:00.900580Z",
     "start_time": "2023-04-17T12:41:00.889582Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path+'disease_Proc_df.pickle', 'rb') as f:\n",
    "    disease_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a93b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:01.435135Z",
     "start_time": "2023-04-17T12:41:01.339334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>State</th>\n",
       "      <th>Tax</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>WA_MALE</th>\n",
       "      <th>WA_FEMALE</th>\n",
       "      <th>BA_MALE</th>\n",
       "      <th>BA_FEMALE</th>\n",
       "      <th>IA_MALE</th>\n",
       "      <th>IA_FEMALE</th>\n",
       "      <th>AA_MALE</th>\n",
       "      <th>AA_FEMALE</th>\n",
       "      <th>NA_MALE</th>\n",
       "      <th>NA_FEMALE</th>\n",
       "      <th>TOM_MALE</th>\n",
       "      <th>TOM_FEMALE</th>\n",
       "      <th>WAC_MALE</th>\n",
       "      <th>WAC_FEMALE</th>\n",
       "      <th>BAC_MALE</th>\n",
       "      <th>BAC_FEMALE</th>\n",
       "      <th>IAC_MALE</th>\n",
       "      <th>IAC_FEMALE</th>\n",
       "      <th>AAC_MALE</th>\n",
       "      <th>AAC_FEMALE</th>\n",
       "      <th>NAC_MALE</th>\n",
       "      <th>NAC_FEMALE</th>\n",
       "      <th>NH_MALE</th>\n",
       "      <th>NH_FEMALE</th>\n",
       "      <th>NHWA_MALE</th>\n",
       "      <th>NHWA_FEMALE</th>\n",
       "      <th>NHBA_MALE</th>\n",
       "      <th>NHBA_FEMALE</th>\n",
       "      <th>NHIA_MALE</th>\n",
       "      <th>NHIA_FEMALE</th>\n",
       "      <th>NHAA_MALE</th>\n",
       "      <th>NHAA_FEMALE</th>\n",
       "      <th>NHNA_MALE</th>\n",
       "      <th>NHNA_FEMALE</th>\n",
       "      <th>NHTOM_MALE</th>\n",
       "      <th>NHTOM_FEMALE</th>\n",
       "      <th>NHWAC_MALE</th>\n",
       "      <th>NHWAC_FEMALE</th>\n",
       "      <th>NHBAC_MALE</th>\n",
       "      <th>NHBAC_FEMALE</th>\n",
       "      <th>NHIAC_MALE</th>\n",
       "      <th>NHIAC_FEMALE</th>\n",
       "      <th>NHAAC_MALE</th>\n",
       "      <th>NHAAC_FEMALE</th>\n",
       "      <th>NHNAC_MALE</th>\n",
       "      <th>NHNAC_FEMALE</th>\n",
       "      <th>H_MALE</th>\n",
       "      <th>H_FEMALE</th>\n",
       "      <th>HWA_MALE</th>\n",
       "      <th>HWA_FEMALE</th>\n",
       "      <th>HBA_MALE</th>\n",
       "      <th>HBA_FEMALE</th>\n",
       "      <th>HIA_MALE</th>\n",
       "      <th>HIA_FEMALE</th>\n",
       "      <th>HAA_MALE</th>\n",
       "      <th>HAA_FEMALE</th>\n",
       "      <th>HNA_MALE</th>\n",
       "      <th>HNA_FEMALE</th>\n",
       "      <th>HTOM_MALE</th>\n",
       "      <th>HTOM_FEMALE</th>\n",
       "      <th>HWAC_MALE</th>\n",
       "      <th>HWAC_FEMALE</th>\n",
       "      <th>HBAC_MALE</th>\n",
       "      <th>HBAC_FEMALE</th>\n",
       "      <th>HIAC_MALE</th>\n",
       "      <th>HIAC_FEMALE</th>\n",
       "      <th>HAAC_MALE</th>\n",
       "      <th>HAAC_FEMALE</th>\n",
       "      <th>HNAC_MALE</th>\n",
       "      <th>HNAC_FEMALE</th>\n",
       "      <th>PRECIP</th>\n",
       "      <th>N_WET_NH4</th>\n",
       "      <th>N_WET_NO3</th>\n",
       "      <th>N_WET</th>\n",
       "      <th>N_DRY_HNO3</th>\n",
       "      <th>N_DRY_NO3</th>\n",
       "      <th>N_DRY_TNO3</th>\n",
       "      <th>N_DRY_NH4</th>\n",
       "      <th>N_DRY_NH3</th>\n",
       "      <th>N_DRY_NH3NET</th>\n",
       "      <th>N_DRY_NOM</th>\n",
       "      <th>N_DRY_NRED</th>\n",
       "      <th>N_DRY_NOXI</th>\n",
       "      <th>N_DRY</th>\n",
       "      <th>S_WET_SO4</th>\n",
       "      <th>S_WET</th>\n",
       "      <th>S_DRY_SO2</th>\n",
       "      <th>S_DRY_SO4</th>\n",
       "      <th>S_DRY</th>\n",
       "      <th>NA_DRY</th>\n",
       "      <th>NA_WET</th>\n",
       "      <th>MG_DRY</th>\n",
       "      <th>MG_WET</th>\n",
       "      <th>K_DRY</th>\n",
       "      <th>K_WET</th>\n",
       "      <th>CA_DRY</th>\n",
       "      <th>CA_WET</th>\n",
       "      <th>CL_DRY</th>\n",
       "      <th>CL_WET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>AL</td>\n",
       "      <td>6747707.0</td>\n",
       "      <td>4785437</td>\n",
       "      <td>2322988</td>\n",
       "      <td>2462449</td>\n",
       "      <td>1657051</td>\n",
       "      <td>1708508</td>\n",
       "      <td>587969</td>\n",
       "      <td>673265</td>\n",
       "      <td>16787</td>\n",
       "      <td>16096</td>\n",
       "      <td>26475</td>\n",
       "      <td>29246</td>\n",
       "      <td>2931</td>\n",
       "      <td>2236</td>\n",
       "      <td>31775</td>\n",
       "      <td>33098</td>\n",
       "      <td>1685590</td>\n",
       "      <td>1737861</td>\n",
       "      <td>602300</td>\n",
       "      <td>688725</td>\n",
       "      <td>31614</td>\n",
       "      <td>31442</td>\n",
       "      <td>32945</td>\n",
       "      <td>36006</td>\n",
       "      <td>4234</td>\n",
       "      <td>3719</td>\n",
       "      <td>2219208</td>\n",
       "      <td>2380041</td>\n",
       "      <td>1570120</td>\n",
       "      <td>1639766</td>\n",
       "      <td>581110</td>\n",
       "      <td>667181</td>\n",
       "      <td>12868</td>\n",
       "      <td>13271</td>\n",
       "      <td>25547</td>\n",
       "      <td>28540</td>\n",
       "      <td>1044</td>\n",
       "      <td>980</td>\n",
       "      <td>28519</td>\n",
       "      <td>30303</td>\n",
       "      <td>1595896</td>\n",
       "      <td>1666780</td>\n",
       "      <td>593948</td>\n",
       "      <td>681290</td>\n",
       "      <td>25967</td>\n",
       "      <td>27204</td>\n",
       "      <td>31378</td>\n",
       "      <td>34691</td>\n",
       "      <td>2003</td>\n",
       "      <td>2131</td>\n",
       "      <td>103780</td>\n",
       "      <td>82408</td>\n",
       "      <td>86931</td>\n",
       "      <td>68742</td>\n",
       "      <td>6859</td>\n",
       "      <td>6084</td>\n",
       "      <td>3919</td>\n",
       "      <td>2825</td>\n",
       "      <td>928</td>\n",
       "      <td>706</td>\n",
       "      <td>1887</td>\n",
       "      <td>1256</td>\n",
       "      <td>3256</td>\n",
       "      <td>2795</td>\n",
       "      <td>89694</td>\n",
       "      <td>71081</td>\n",
       "      <td>8352</td>\n",
       "      <td>7435</td>\n",
       "      <td>5647</td>\n",
       "      <td>4238</td>\n",
       "      <td>1567</td>\n",
       "      <td>1315</td>\n",
       "      <td>2231</td>\n",
       "      <td>1588</td>\n",
       "      <td>131.225000</td>\n",
       "      <td>2.506000</td>\n",
       "      <td>2.165000</td>\n",
       "      <td>4.67200</td>\n",
       "      <td>4.173000</td>\n",
       "      <td>0.286000</td>\n",
       "      <td>4.460000</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>1.535000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>1.932000</td>\n",
       "      <td>1.933000</td>\n",
       "      <td>6.391000</td>\n",
       "      <td>8.324000</td>\n",
       "      <td>4.921000</td>\n",
       "      <td>4.921000</td>\n",
       "      <td>6.638000</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>6.956000</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>1.27300</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.551000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>2.245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>AR</td>\n",
       "      <td>4986747.0</td>\n",
       "      <td>2921964</td>\n",
       "      <td>1434724</td>\n",
       "      <td>1487240</td>\n",
       "      <td>1159262</td>\n",
       "      <td>1187080</td>\n",
       "      <td>216407</td>\n",
       "      <td>238623</td>\n",
       "      <td>13178</td>\n",
       "      <td>13073</td>\n",
       "      <td>17947</td>\n",
       "      <td>20008</td>\n",
       "      <td>3573</td>\n",
       "      <td>3235</td>\n",
       "      <td>24357</td>\n",
       "      <td>25221</td>\n",
       "      <td>1181927</td>\n",
       "      <td>1210463</td>\n",
       "      <td>225508</td>\n",
       "      <td>248179</td>\n",
       "      <td>26094</td>\n",
       "      <td>26536</td>\n",
       "      <td>22225</td>\n",
       "      <td>24394</td>\n",
       "      <td>4576</td>\n",
       "      <td>4239</td>\n",
       "      <td>1334757</td>\n",
       "      <td>1399725</td>\n",
       "      <td>1069598</td>\n",
       "      <td>1108709</td>\n",
       "      <td>213186</td>\n",
       "      <td>235651</td>\n",
       "      <td>10003</td>\n",
       "      <td>10377</td>\n",
       "      <td>17181</td>\n",
       "      <td>19327</td>\n",
       "      <td>2952</td>\n",
       "      <td>2803</td>\n",
       "      <td>21837</td>\n",
       "      <td>22858</td>\n",
       "      <td>1089955</td>\n",
       "      <td>1129934</td>\n",
       "      <td>221472</td>\n",
       "      <td>244476</td>\n",
       "      <td>21388</td>\n",
       "      <td>22340</td>\n",
       "      <td>20970</td>\n",
       "      <td>23271</td>\n",
       "      <td>3745</td>\n",
       "      <td>3615</td>\n",
       "      <td>99967</td>\n",
       "      <td>87515</td>\n",
       "      <td>89664</td>\n",
       "      <td>78371</td>\n",
       "      <td>3221</td>\n",
       "      <td>2972</td>\n",
       "      <td>3175</td>\n",
       "      <td>2696</td>\n",
       "      <td>766</td>\n",
       "      <td>681</td>\n",
       "      <td>621</td>\n",
       "      <td>432</td>\n",
       "      <td>2520</td>\n",
       "      <td>2363</td>\n",
       "      <td>91972</td>\n",
       "      <td>80529</td>\n",
       "      <td>4036</td>\n",
       "      <td>3703</td>\n",
       "      <td>4706</td>\n",
       "      <td>4196</td>\n",
       "      <td>1255</td>\n",
       "      <td>1123</td>\n",
       "      <td>831</td>\n",
       "      <td>624</td>\n",
       "      <td>151.199000</td>\n",
       "      <td>1.507000</td>\n",
       "      <td>2.241000</td>\n",
       "      <td>3.74800</td>\n",
       "      <td>3.314000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>3.391000</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>1.217000</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>1.516000</td>\n",
       "      <td>1.450000</td>\n",
       "      <td>4.907000</td>\n",
       "      <td>6.356000</td>\n",
       "      <td>4.147000</td>\n",
       "      <td>4.147000</td>\n",
       "      <td>1.446000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>1.44200</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>1.754000</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>2.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>AZ</td>\n",
       "      <td>8360376.0</td>\n",
       "      <td>6407172</td>\n",
       "      <td>3183922</td>\n",
       "      <td>3223250</td>\n",
       "      <td>2696389</td>\n",
       "      <td>2731840</td>\n",
       "      <td>147100</td>\n",
       "      <td>135101</td>\n",
       "      <td>166315</td>\n",
       "      <td>170237</td>\n",
       "      <td>88871</td>\n",
       "      <td>101197</td>\n",
       "      <td>8736</td>\n",
       "      <td>7438</td>\n",
       "      <td>76511</td>\n",
       "      <td>77437</td>\n",
       "      <td>2764637</td>\n",
       "      <td>2801049</td>\n",
       "      <td>175874</td>\n",
       "      <td>164602</td>\n",
       "      <td>195792</td>\n",
       "      <td>200093</td>\n",
       "      <td>115867</td>\n",
       "      <td>128081</td>\n",
       "      <td>14823</td>\n",
       "      <td>13710</td>\n",
       "      <td>2227904</td>\n",
       "      <td>2275834</td>\n",
       "      <td>1832998</td>\n",
       "      <td>1874603</td>\n",
       "      <td>127328</td>\n",
       "      <td>114756</td>\n",
       "      <td>126085</td>\n",
       "      <td>132838</td>\n",
       "      <td>80886</td>\n",
       "      <td>93087</td>\n",
       "      <td>6227</td>\n",
       "      <td>4972</td>\n",
       "      <td>54380</td>\n",
       "      <td>55578</td>\n",
       "      <td>1881277</td>\n",
       "      <td>1924208</td>\n",
       "      <td>148948</td>\n",
       "      <td>136943</td>\n",
       "      <td>143929</td>\n",
       "      <td>151411</td>\n",
       "      <td>101659</td>\n",
       "      <td>113694</td>\n",
       "      <td>10680</td>\n",
       "      <td>9669</td>\n",
       "      <td>956018</td>\n",
       "      <td>947416</td>\n",
       "      <td>863391</td>\n",
       "      <td>857237</td>\n",
       "      <td>19772</td>\n",
       "      <td>20345</td>\n",
       "      <td>40230</td>\n",
       "      <td>37399</td>\n",
       "      <td>7985</td>\n",
       "      <td>8110</td>\n",
       "      <td>2509</td>\n",
       "      <td>2466</td>\n",
       "      <td>22131</td>\n",
       "      <td>21859</td>\n",
       "      <td>883360</td>\n",
       "      <td>876841</td>\n",
       "      <td>26926</td>\n",
       "      <td>27659</td>\n",
       "      <td>51863</td>\n",
       "      <td>48682</td>\n",
       "      <td>14208</td>\n",
       "      <td>14387</td>\n",
       "      <td>4143</td>\n",
       "      <td>4041</td>\n",
       "      <td>34.533333</td>\n",
       "      <td>0.549667</td>\n",
       "      <td>0.827333</td>\n",
       "      <td>1.37700</td>\n",
       "      <td>1.498000</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>1.605667</td>\n",
       "      <td>0.113667</td>\n",
       "      <td>0.365667</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>0.253000</td>\n",
       "      <td>0.479333</td>\n",
       "      <td>1.858333</td>\n",
       "      <td>2.337667</td>\n",
       "      <td>0.823667</td>\n",
       "      <td>0.823667</td>\n",
       "      <td>0.369667</td>\n",
       "      <td>0.104333</td>\n",
       "      <td>0.474333</td>\n",
       "      <td>0.126333</td>\n",
       "      <td>0.23300</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.038667</td>\n",
       "      <td>0.140667</td>\n",
       "      <td>0.269667</td>\n",
       "      <td>0.934667</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.423667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>CA</td>\n",
       "      <td>90453746.0</td>\n",
       "      <td>37319502</td>\n",
       "      <td>18545938</td>\n",
       "      <td>18773564</td>\n",
       "      <td>13871272</td>\n",
       "      <td>13797795</td>\n",
       "      <td>1225792</td>\n",
       "      <td>1260514</td>\n",
       "      <td>317587</td>\n",
       "      <td>305568</td>\n",
       "      <td>2401000</td>\n",
       "      <td>2660686</td>\n",
       "      <td>90582</td>\n",
       "      <td>91510</td>\n",
       "      <td>639705</td>\n",
       "      <td>657491</td>\n",
       "      <td>14431194</td>\n",
       "      <td>14370439</td>\n",
       "      <td>1406290</td>\n",
       "      <td>1452701</td>\n",
       "      <td>515335</td>\n",
       "      <td>513789</td>\n",
       "      <td>2735187</td>\n",
       "      <td>2998110</td>\n",
       "      <td>158158</td>\n",
       "      <td>162417</td>\n",
       "      <td>11444589</td>\n",
       "      <td>11812292</td>\n",
       "      <td>7476718</td>\n",
       "      <td>7540429</td>\n",
       "      <td>1079499</td>\n",
       "      <td>1106783</td>\n",
       "      <td>81451</td>\n",
       "      <td>83010</td>\n",
       "      <td>2291144</td>\n",
       "      <td>2548642</td>\n",
       "      <td>66055</td>\n",
       "      <td>67172</td>\n",
       "      <td>449722</td>\n",
       "      <td>466256</td>\n",
       "      <td>7866977</td>\n",
       "      <td>7942953</td>\n",
       "      <td>1208391</td>\n",
       "      <td>1245386</td>\n",
       "      <td>186916</td>\n",
       "      <td>199270</td>\n",
       "      <td>2553652</td>\n",
       "      <td>2813588</td>\n",
       "      <td>115621</td>\n",
       "      <td>119703</td>\n",
       "      <td>7101349</td>\n",
       "      <td>6961272</td>\n",
       "      <td>6394554</td>\n",
       "      <td>6257366</td>\n",
       "      <td>146293</td>\n",
       "      <td>153731</td>\n",
       "      <td>236136</td>\n",
       "      <td>222558</td>\n",
       "      <td>109856</td>\n",
       "      <td>112044</td>\n",
       "      <td>24527</td>\n",
       "      <td>24338</td>\n",
       "      <td>189983</td>\n",
       "      <td>191235</td>\n",
       "      <td>6564217</td>\n",
       "      <td>6427486</td>\n",
       "      <td>197899</td>\n",
       "      <td>207315</td>\n",
       "      <td>328419</td>\n",
       "      <td>314519</td>\n",
       "      <td>181535</td>\n",
       "      <td>184522</td>\n",
       "      <td>42537</td>\n",
       "      <td>42714</td>\n",
       "      <td>58.153625</td>\n",
       "      <td>1.176000</td>\n",
       "      <td>0.892625</td>\n",
       "      <td>2.06875</td>\n",
       "      <td>3.764625</td>\n",
       "      <td>0.248125</td>\n",
       "      <td>4.012500</td>\n",
       "      <td>0.226250</td>\n",
       "      <td>2.296750</td>\n",
       "      <td>2.054875</td>\n",
       "      <td>0.449625</td>\n",
       "      <td>2.522625</td>\n",
       "      <td>4.462250</td>\n",
       "      <td>6.984875</td>\n",
       "      <td>0.590750</td>\n",
       "      <td>0.590750</td>\n",
       "      <td>0.419875</td>\n",
       "      <td>0.124625</td>\n",
       "      <td>0.544375</td>\n",
       "      <td>0.288750</td>\n",
       "      <td>0.73975</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.070250</td>\n",
       "      <td>0.104875</td>\n",
       "      <td>0.261250</td>\n",
       "      <td>0.467375</td>\n",
       "      <td>0.088375</td>\n",
       "      <td>1.249750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>CO</td>\n",
       "      <td>7566919.0</td>\n",
       "      <td>5047349</td>\n",
       "      <td>2529516</td>\n",
       "      <td>2517833</td>\n",
       "      <td>2238772</td>\n",
       "      <td>2225593</td>\n",
       "      <td>113617</td>\n",
       "      <td>102504</td>\n",
       "      <td>40083</td>\n",
       "      <td>38398</td>\n",
       "      <td>66774</td>\n",
       "      <td>79571</td>\n",
       "      <td>4308</td>\n",
       "      <td>4195</td>\n",
       "      <td>65962</td>\n",
       "      <td>67572</td>\n",
       "      <td>2299050</td>\n",
       "      <td>2287489</td>\n",
       "      <td>136897</td>\n",
       "      <td>126324</td>\n",
       "      <td>67019</td>\n",
       "      <td>66500</td>\n",
       "      <td>89838</td>\n",
       "      <td>102952</td>\n",
       "      <td>8524</td>\n",
       "      <td>8463</td>\n",
       "      <td>1996915</td>\n",
       "      <td>2005835</td>\n",
       "      <td>1765551</td>\n",
       "      <td>1772536</td>\n",
       "      <td>101424</td>\n",
       "      <td>89872</td>\n",
       "      <td>16073</td>\n",
       "      <td>15560</td>\n",
       "      <td>62791</td>\n",
       "      <td>75576</td>\n",
       "      <td>2947</td>\n",
       "      <td>2853</td>\n",
       "      <td>48129</td>\n",
       "      <td>49438</td>\n",
       "      <td>1809559</td>\n",
       "      <td>1817823</td>\n",
       "      <td>119266</td>\n",
       "      <td>108286</td>\n",
       "      <td>32019</td>\n",
       "      <td>32378</td>\n",
       "      <td>81968</td>\n",
       "      <td>95006</td>\n",
       "      <td>6111</td>\n",
       "      <td>6058</td>\n",
       "      <td>532601</td>\n",
       "      <td>511998</td>\n",
       "      <td>473221</td>\n",
       "      <td>453057</td>\n",
       "      <td>12193</td>\n",
       "      <td>12632</td>\n",
       "      <td>24010</td>\n",
       "      <td>22838</td>\n",
       "      <td>3983</td>\n",
       "      <td>3995</td>\n",
       "      <td>1361</td>\n",
       "      <td>1342</td>\n",
       "      <td>17833</td>\n",
       "      <td>18134</td>\n",
       "      <td>489491</td>\n",
       "      <td>469666</td>\n",
       "      <td>17631</td>\n",
       "      <td>18038</td>\n",
       "      <td>35000</td>\n",
       "      <td>34122</td>\n",
       "      <td>7870</td>\n",
       "      <td>7946</td>\n",
       "      <td>2413</td>\n",
       "      <td>2405</td>\n",
       "      <td>55.322000</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>1.81650</td>\n",
       "      <td>1.412250</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>1.636250</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.331500</td>\n",
       "      <td>0.198750</td>\n",
       "      <td>0.282750</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>1.919250</td>\n",
       "      <td>2.425500</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.842750</td>\n",
       "      <td>0.274500</td>\n",
       "      <td>0.133000</td>\n",
       "      <td>0.407500</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.15750</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.275250</td>\n",
       "      <td>0.910750</td>\n",
       "      <td>0.048250</td>\n",
       "      <td>0.270750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>2019</td>\n",
       "      <td>VT</td>\n",
       "      <td>3493747.0</td>\n",
       "      <td>623989</td>\n",
       "      <td>308316</td>\n",
       "      <td>315673</td>\n",
       "      <td>290404</td>\n",
       "      <td>297698</td>\n",
       "      <td>5035</td>\n",
       "      <td>3739</td>\n",
       "      <td>1250</td>\n",
       "      <td>1191</td>\n",
       "      <td>5351</td>\n",
       "      <td>6613</td>\n",
       "      <td>136</td>\n",
       "      <td>111</td>\n",
       "      <td>6140</td>\n",
       "      <td>6321</td>\n",
       "      <td>296362</td>\n",
       "      <td>303854</td>\n",
       "      <td>7164</td>\n",
       "      <td>5869</td>\n",
       "      <td>4007</td>\n",
       "      <td>4081</td>\n",
       "      <td>6945</td>\n",
       "      <td>8294</td>\n",
       "      <td>341</td>\n",
       "      <td>297</td>\n",
       "      <td>301880</td>\n",
       "      <td>309390</td>\n",
       "      <td>285070</td>\n",
       "      <td>292469</td>\n",
       "      <td>4693</td>\n",
       "      <td>3459</td>\n",
       "      <td>1038</td>\n",
       "      <td>1020</td>\n",
       "      <td>5278</td>\n",
       "      <td>6535</td>\n",
       "      <td>110</td>\n",
       "      <td>87</td>\n",
       "      <td>5691</td>\n",
       "      <td>5820</td>\n",
       "      <td>290621</td>\n",
       "      <td>298165</td>\n",
       "      <td>6565</td>\n",
       "      <td>5313</td>\n",
       "      <td>3586</td>\n",
       "      <td>3675</td>\n",
       "      <td>6798</td>\n",
       "      <td>8131</td>\n",
       "      <td>293</td>\n",
       "      <td>261</td>\n",
       "      <td>6436</td>\n",
       "      <td>6283</td>\n",
       "      <td>5334</td>\n",
       "      <td>5229</td>\n",
       "      <td>342</td>\n",
       "      <td>280</td>\n",
       "      <td>212</td>\n",
       "      <td>171</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>449</td>\n",
       "      <td>501</td>\n",
       "      <td>5741</td>\n",
       "      <td>5689</td>\n",
       "      <td>599</td>\n",
       "      <td>556</td>\n",
       "      <td>421</td>\n",
       "      <td>406</td>\n",
       "      <td>147</td>\n",
       "      <td>163</td>\n",
       "      <td>48</td>\n",
       "      <td>36</td>\n",
       "      <td>160.718000</td>\n",
       "      <td>2.853500</td>\n",
       "      <td>2.368500</td>\n",
       "      <td>5.22200</td>\n",
       "      <td>1.118500</td>\n",
       "      <td>0.099500</td>\n",
       "      <td>1.218000</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>1.460000</td>\n",
       "      <td>1.300500</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>1.593000</td>\n",
       "      <td>1.686500</td>\n",
       "      <td>3.279500</td>\n",
       "      <td>1.647000</td>\n",
       "      <td>1.647000</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.82700</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>1.525000</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>1.424500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2019</td>\n",
       "      <td>WA</td>\n",
       "      <td>27992437.0</td>\n",
       "      <td>7614893</td>\n",
       "      <td>3811983</td>\n",
       "      <td>3802910</td>\n",
       "      <td>2998778</td>\n",
       "      <td>2978918</td>\n",
       "      <td>179227</td>\n",
       "      <td>152697</td>\n",
       "      <td>74471</td>\n",
       "      <td>72328</td>\n",
       "      <td>344066</td>\n",
       "      <td>383920</td>\n",
       "      <td>30461</td>\n",
       "      <td>29888</td>\n",
       "      <td>184980</td>\n",
       "      <td>185159</td>\n",
       "      <td>3166201</td>\n",
       "      <td>3147166</td>\n",
       "      <td>239976</td>\n",
       "      <td>212328</td>\n",
       "      <td>131948</td>\n",
       "      <td>132648</td>\n",
       "      <td>429290</td>\n",
       "      <td>467608</td>\n",
       "      <td>50165</td>\n",
       "      <td>49446</td>\n",
       "      <td>3300251</td>\n",
       "      <td>3322921</td>\n",
       "      <td>2566643</td>\n",
       "      <td>2573946</td>\n",
       "      <td>164766</td>\n",
       "      <td>139458</td>\n",
       "      <td>48114</td>\n",
       "      <td>48392</td>\n",
       "      <td>335777</td>\n",
       "      <td>375849</td>\n",
       "      <td>27465</td>\n",
       "      <td>27168</td>\n",
       "      <td>157486</td>\n",
       "      <td>158108</td>\n",
       "      <td>2709525</td>\n",
       "      <td>2717974</td>\n",
       "      <td>216129</td>\n",
       "      <td>190100</td>\n",
       "      <td>91829</td>\n",
       "      <td>95394</td>\n",
       "      <td>411989</td>\n",
       "      <td>450292</td>\n",
       "      <td>44333</td>\n",
       "      <td>43654</td>\n",
       "      <td>511732</td>\n",
       "      <td>479989</td>\n",
       "      <td>432135</td>\n",
       "      <td>404972</td>\n",
       "      <td>14461</td>\n",
       "      <td>13239</td>\n",
       "      <td>26357</td>\n",
       "      <td>23936</td>\n",
       "      <td>8289</td>\n",
       "      <td>8071</td>\n",
       "      <td>2996</td>\n",
       "      <td>2720</td>\n",
       "      <td>27494</td>\n",
       "      <td>27051</td>\n",
       "      <td>456676</td>\n",
       "      <td>429192</td>\n",
       "      <td>23847</td>\n",
       "      <td>22228</td>\n",
       "      <td>40119</td>\n",
       "      <td>37254</td>\n",
       "      <td>17301</td>\n",
       "      <td>17316</td>\n",
       "      <td>5832</td>\n",
       "      <td>5792</td>\n",
       "      <td>107.980750</td>\n",
       "      <td>0.456500</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.95075</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.040750</td>\n",
       "      <td>0.940750</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>0.641750</td>\n",
       "      <td>-0.171500</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>1.354750</td>\n",
       "      <td>2.074750</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.208750</td>\n",
       "      <td>0.088250</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>2.19850</td>\n",
       "      <td>0.052250</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.171250</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.321750</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>4.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2019</td>\n",
       "      <td>WI</td>\n",
       "      <td>19871532.0</td>\n",
       "      <td>5822434</td>\n",
       "      <td>2897209</td>\n",
       "      <td>2925225</td>\n",
       "      <td>2525105</td>\n",
       "      <td>2542676</td>\n",
       "      <td>192304</td>\n",
       "      <td>198239</td>\n",
       "      <td>34462</td>\n",
       "      <td>34166</td>\n",
       "      <td>85324</td>\n",
       "      <td>89955</td>\n",
       "      <td>1803</td>\n",
       "      <td>1616</td>\n",
       "      <td>58211</td>\n",
       "      <td>58573</td>\n",
       "      <td>2579628</td>\n",
       "      <td>2597425</td>\n",
       "      <td>222647</td>\n",
       "      <td>229084</td>\n",
       "      <td>52945</td>\n",
       "      <td>53257</td>\n",
       "      <td>100201</td>\n",
       "      <td>104555</td>\n",
       "      <td>3952</td>\n",
       "      <td>3629</td>\n",
       "      <td>2684581</td>\n",
       "      <td>2724645</td>\n",
       "      <td>2340129</td>\n",
       "      <td>2368936</td>\n",
       "      <td>183054</td>\n",
       "      <td>189219</td>\n",
       "      <td>26174</td>\n",
       "      <td>26262</td>\n",
       "      <td>83777</td>\n",
       "      <td>88428</td>\n",
       "      <td>1224</td>\n",
       "      <td>1094</td>\n",
       "      <td>50223</td>\n",
       "      <td>50706</td>\n",
       "      <td>2387323</td>\n",
       "      <td>2416467</td>\n",
       "      <td>209109</td>\n",
       "      <td>215816</td>\n",
       "      <td>40801</td>\n",
       "      <td>41610</td>\n",
       "      <td>97477</td>\n",
       "      <td>101821</td>\n",
       "      <td>3034</td>\n",
       "      <td>2813</td>\n",
       "      <td>212628</td>\n",
       "      <td>200580</td>\n",
       "      <td>184976</td>\n",
       "      <td>173740</td>\n",
       "      <td>9250</td>\n",
       "      <td>9020</td>\n",
       "      <td>8288</td>\n",
       "      <td>7904</td>\n",
       "      <td>1547</td>\n",
       "      <td>1527</td>\n",
       "      <td>579</td>\n",
       "      <td>522</td>\n",
       "      <td>7988</td>\n",
       "      <td>7867</td>\n",
       "      <td>192305</td>\n",
       "      <td>180958</td>\n",
       "      <td>13538</td>\n",
       "      <td>13268</td>\n",
       "      <td>12144</td>\n",
       "      <td>11647</td>\n",
       "      <td>2724</td>\n",
       "      <td>2734</td>\n",
       "      <td>918</td>\n",
       "      <td>816</td>\n",
       "      <td>130.666000</td>\n",
       "      <td>5.162000</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>7.11100</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>1.174000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>3.733000</td>\n",
       "      <td>3.415000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>3.908000</td>\n",
       "      <td>1.596000</td>\n",
       "      <td>5.504000</td>\n",
       "      <td>1.457000</td>\n",
       "      <td>1.457000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.24900</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>3.094000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>2019</td>\n",
       "      <td>WV</td>\n",
       "      <td>5792317.0</td>\n",
       "      <td>1792147</td>\n",
       "      <td>887770</td>\n",
       "      <td>904377</td>\n",
       "      <td>826647</td>\n",
       "      <td>848475</td>\n",
       "      <td>35072</td>\n",
       "      <td>29538</td>\n",
       "      <td>2444</td>\n",
       "      <td>2141</td>\n",
       "      <td>6904</td>\n",
       "      <td>7799</td>\n",
       "      <td>261</td>\n",
       "      <td>269</td>\n",
       "      <td>16442</td>\n",
       "      <td>16155</td>\n",
       "      <td>842435</td>\n",
       "      <td>864002</td>\n",
       "      <td>44492</td>\n",
       "      <td>38824</td>\n",
       "      <td>7710</td>\n",
       "      <td>7427</td>\n",
       "      <td>9708</td>\n",
       "      <td>10423</td>\n",
       "      <td>776</td>\n",
       "      <td>811</td>\n",
       "      <td>871023</td>\n",
       "      <td>889962</td>\n",
       "      <td>812413</td>\n",
       "      <td>836099</td>\n",
       "      <td>34026</td>\n",
       "      <td>28749</td>\n",
       "      <td>2012</td>\n",
       "      <td>1824</td>\n",
       "      <td>6733</td>\n",
       "      <td>7660</td>\n",
       "      <td>202</td>\n",
       "      <td>209</td>\n",
       "      <td>15637</td>\n",
       "      <td>15421</td>\n",
       "      <td>827469</td>\n",
       "      <td>850948</td>\n",
       "      <td>42992</td>\n",
       "      <td>37656</td>\n",
       "      <td>6923</td>\n",
       "      <td>6755</td>\n",
       "      <td>9350</td>\n",
       "      <td>10136</td>\n",
       "      <td>661</td>\n",
       "      <td>669</td>\n",
       "      <td>16747</td>\n",
       "      <td>14415</td>\n",
       "      <td>14234</td>\n",
       "      <td>12376</td>\n",
       "      <td>1046</td>\n",
       "      <td>789</td>\n",
       "      <td>432</td>\n",
       "      <td>317</td>\n",
       "      <td>171</td>\n",
       "      <td>139</td>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>805</td>\n",
       "      <td>734</td>\n",
       "      <td>14966</td>\n",
       "      <td>13054</td>\n",
       "      <td>1500</td>\n",
       "      <td>1168</td>\n",
       "      <td>787</td>\n",
       "      <td>672</td>\n",
       "      <td>358</td>\n",
       "      <td>287</td>\n",
       "      <td>115</td>\n",
       "      <td>142</td>\n",
       "      <td>123.584000</td>\n",
       "      <td>1.982000</td>\n",
       "      <td>1.601500</td>\n",
       "      <td>3.58300</td>\n",
       "      <td>1.309000</td>\n",
       "      <td>0.082500</td>\n",
       "      <td>1.392000</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>1.523000</td>\n",
       "      <td>1.121000</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>1.696000</td>\n",
       "      <td>2.377000</td>\n",
       "      <td>4.073500</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.36850</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>0.239500</td>\n",
       "      <td>1.209500</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2019</td>\n",
       "      <td>WY</td>\n",
       "      <td>2110704.0</td>\n",
       "      <td>578759</td>\n",
       "      <td>294730</td>\n",
       "      <td>284029</td>\n",
       "      <td>272532</td>\n",
       "      <td>262839</td>\n",
       "      <td>4408</td>\n",
       "      <td>3059</td>\n",
       "      <td>7966</td>\n",
       "      <td>7812</td>\n",
       "      <td>2965</td>\n",
       "      <td>3606</td>\n",
       "      <td>321</td>\n",
       "      <td>275</td>\n",
       "      <td>6538</td>\n",
       "      <td>6438</td>\n",
       "      <td>278795</td>\n",
       "      <td>268976</td>\n",
       "      <td>6340</td>\n",
       "      <td>5029</td>\n",
       "      <td>11162</td>\n",
       "      <td>10862</td>\n",
       "      <td>4612</td>\n",
       "      <td>5280</td>\n",
       "      <td>746</td>\n",
       "      <td>688</td>\n",
       "      <td>263998</td>\n",
       "      <td>256152</td>\n",
       "      <td>245795</td>\n",
       "      <td>238585</td>\n",
       "      <td>3926</td>\n",
       "      <td>2594</td>\n",
       "      <td>6036</td>\n",
       "      <td>6162</td>\n",
       "      <td>2730</td>\n",
       "      <td>3399</td>\n",
       "      <td>221</td>\n",
       "      <td>191</td>\n",
       "      <td>5290</td>\n",
       "      <td>5221</td>\n",
       "      <td>250881</td>\n",
       "      <td>243599</td>\n",
       "      <td>5469</td>\n",
       "      <td>4178</td>\n",
       "      <td>8465</td>\n",
       "      <td>8456</td>\n",
       "      <td>4187</td>\n",
       "      <td>4841</td>\n",
       "      <td>558</td>\n",
       "      <td>539</td>\n",
       "      <td>30732</td>\n",
       "      <td>27877</td>\n",
       "      <td>26737</td>\n",
       "      <td>24254</td>\n",
       "      <td>482</td>\n",
       "      <td>465</td>\n",
       "      <td>1930</td>\n",
       "      <td>1650</td>\n",
       "      <td>235</td>\n",
       "      <td>207</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>1248</td>\n",
       "      <td>1217</td>\n",
       "      <td>27914</td>\n",
       "      <td>25377</td>\n",
       "      <td>871</td>\n",
       "      <td>851</td>\n",
       "      <td>2697</td>\n",
       "      <td>2406</td>\n",
       "      <td>425</td>\n",
       "      <td>439</td>\n",
       "      <td>188</td>\n",
       "      <td>149</td>\n",
       "      <td>57.293000</td>\n",
       "      <td>1.233500</td>\n",
       "      <td>0.676875</td>\n",
       "      <td>1.91025</td>\n",
       "      <td>0.445500</td>\n",
       "      <td>0.060750</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.516500</td>\n",
       "      <td>0.282375</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.594875</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>1.265750</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.486375</td>\n",
       "      <td>0.198500</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.236625</td>\n",
       "      <td>0.035625</td>\n",
       "      <td>0.19725</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.027250</td>\n",
       "      <td>0.109750</td>\n",
       "      <td>0.167250</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.370750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows Ã— 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year State         Tax   TOT_POP  TOT_MALE  TOT_FEMALE   WA_MALE  \\\n",
       "0    2001    AL   6747707.0   4785437   2322988     2462449   1657051   \n",
       "1    2001    AR   4986747.0   2921964   1434724     1487240   1159262   \n",
       "2    2001    AZ   8360376.0   6407172   3183922     3223250   2696389   \n",
       "3    2001    CA  90453746.0  37319502  18545938    18773564  13871272   \n",
       "4    2001    CO   7566919.0   5047349   2529516     2517833   2238772   \n",
       "..    ...   ...         ...       ...       ...         ...       ...   \n",
       "736  2019    VT   3493747.0    623989    308316      315673    290404   \n",
       "737  2019    WA  27992437.0   7614893   3811983     3802910   2998778   \n",
       "738  2019    WI  19871532.0   5822434   2897209     2925225   2525105   \n",
       "739  2019    WV   5792317.0   1792147    887770      904377    826647   \n",
       "740  2019    WY   2110704.0    578759    294730      284029    272532   \n",
       "\n",
       "     WA_FEMALE  BA_MALE  BA_FEMALE  IA_MALE  IA_FEMALE  AA_MALE  AA_FEMALE  \\\n",
       "0      1708508   587969     673265    16787      16096    26475      29246   \n",
       "1      1187080   216407     238623    13178      13073    17947      20008   \n",
       "2      2731840   147100     135101   166315     170237    88871     101197   \n",
       "3     13797795  1225792    1260514   317587     305568  2401000    2660686   \n",
       "4      2225593   113617     102504    40083      38398    66774      79571   \n",
       "..         ...      ...        ...      ...        ...      ...        ...   \n",
       "736     297698     5035       3739     1250       1191     5351       6613   \n",
       "737    2978918   179227     152697    74471      72328   344066     383920   \n",
       "738    2542676   192304     198239    34462      34166    85324      89955   \n",
       "739     848475    35072      29538     2444       2141     6904       7799   \n",
       "740     262839     4408       3059     7966       7812     2965       3606   \n",
       "\n",
       "     NA_MALE  NA_FEMALE  TOM_MALE  TOM_FEMALE  WAC_MALE  WAC_FEMALE  BAC_MALE  \\\n",
       "0       2931       2236     31775       33098   1685590     1737861    602300   \n",
       "1       3573       3235     24357       25221   1181927     1210463    225508   \n",
       "2       8736       7438     76511       77437   2764637     2801049    175874   \n",
       "3      90582      91510    639705      657491  14431194    14370439   1406290   \n",
       "4       4308       4195     65962       67572   2299050     2287489    136897   \n",
       "..       ...        ...       ...         ...       ...         ...       ...   \n",
       "736      136        111      6140        6321    296362      303854      7164   \n",
       "737    30461      29888    184980      185159   3166201     3147166    239976   \n",
       "738     1803       1616     58211       58573   2579628     2597425    222647   \n",
       "739      261        269     16442       16155    842435      864002     44492   \n",
       "740      321        275      6538        6438    278795      268976      6340   \n",
       "\n",
       "     BAC_FEMALE  IAC_MALE  IAC_FEMALE  AAC_MALE  AAC_FEMALE  NAC_MALE  \\\n",
       "0        688725     31614       31442     32945       36006      4234   \n",
       "1        248179     26094       26536     22225       24394      4576   \n",
       "2        164602    195792      200093    115867      128081     14823   \n",
       "3       1452701    515335      513789   2735187     2998110    158158   \n",
       "4        126324     67019       66500     89838      102952      8524   \n",
       "..          ...       ...         ...       ...         ...       ...   \n",
       "736        5869      4007        4081      6945        8294       341   \n",
       "737      212328    131948      132648    429290      467608     50165   \n",
       "738      229084     52945       53257    100201      104555      3952   \n",
       "739       38824      7710        7427      9708       10423       776   \n",
       "740        5029     11162       10862      4612        5280       746   \n",
       "\n",
       "     NAC_FEMALE   NH_MALE  NH_FEMALE  NHWA_MALE  NHWA_FEMALE  NHBA_MALE  \\\n",
       "0          3719   2219208    2380041    1570120      1639766     581110   \n",
       "1          4239   1334757    1399725    1069598      1108709     213186   \n",
       "2         13710   2227904    2275834    1832998      1874603     127328   \n",
       "3        162417  11444589   11812292    7476718      7540429    1079499   \n",
       "4          8463   1996915    2005835    1765551      1772536     101424   \n",
       "..          ...       ...        ...        ...          ...        ...   \n",
       "736         297    301880     309390     285070       292469       4693   \n",
       "737       49446   3300251    3322921    2566643      2573946     164766   \n",
       "738        3629   2684581    2724645    2340129      2368936     183054   \n",
       "739         811    871023     889962     812413       836099      34026   \n",
       "740         688    263998     256152     245795       238585       3926   \n",
       "\n",
       "     NHBA_FEMALE  NHIA_MALE  NHIA_FEMALE  NHAA_MALE  NHAA_FEMALE  NHNA_MALE  \\\n",
       "0         667181      12868        13271      25547        28540       1044   \n",
       "1         235651      10003        10377      17181        19327       2952   \n",
       "2         114756     126085       132838      80886        93087       6227   \n",
       "3        1106783      81451        83010    2291144      2548642      66055   \n",
       "4          89872      16073        15560      62791        75576       2947   \n",
       "..           ...        ...          ...        ...          ...        ...   \n",
       "736         3459       1038         1020       5278         6535        110   \n",
       "737       139458      48114        48392     335777       375849      27465   \n",
       "738       189219      26174        26262      83777        88428       1224   \n",
       "739        28749       2012         1824       6733         7660        202   \n",
       "740         2594       6036         6162       2730         3399        221   \n",
       "\n",
       "     NHNA_FEMALE  NHTOM_MALE  NHTOM_FEMALE  NHWAC_MALE  NHWAC_FEMALE  \\\n",
       "0            980       28519         30303     1595896       1666780   \n",
       "1           2803       21837         22858     1089955       1129934   \n",
       "2           4972       54380         55578     1881277       1924208   \n",
       "3          67172      449722        466256     7866977       7942953   \n",
       "4           2853       48129         49438     1809559       1817823   \n",
       "..           ...         ...           ...         ...           ...   \n",
       "736           87        5691          5820      290621        298165   \n",
       "737        27168      157486        158108     2709525       2717974   \n",
       "738         1094       50223         50706     2387323       2416467   \n",
       "739          209       15637         15421      827469        850948   \n",
       "740          191        5290          5221      250881        243599   \n",
       "\n",
       "     NHBAC_MALE  NHBAC_FEMALE  NHIAC_MALE  NHIAC_FEMALE  NHAAC_MALE  \\\n",
       "0        593948        681290       25967         27204       31378   \n",
       "1        221472        244476       21388         22340       20970   \n",
       "2        148948        136943      143929        151411      101659   \n",
       "3       1208391       1245386      186916        199270     2553652   \n",
       "4        119266        108286       32019         32378       81968   \n",
       "..          ...           ...         ...           ...         ...   \n",
       "736        6565          5313        3586          3675        6798   \n",
       "737      216129        190100       91829         95394      411989   \n",
       "738      209109        215816       40801         41610       97477   \n",
       "739       42992         37656        6923          6755        9350   \n",
       "740        5469          4178        8465          8456        4187   \n",
       "\n",
       "     NHAAC_FEMALE  NHNAC_MALE  NHNAC_FEMALE   H_MALE  H_FEMALE  HWA_MALE  \\\n",
       "0           34691        2003          2131   103780     82408     86931   \n",
       "1           23271        3745          3615    99967     87515     89664   \n",
       "2          113694       10680          9669   956018    947416    863391   \n",
       "3         2813588      115621        119703  7101349   6961272   6394554   \n",
       "4           95006        6111          6058   532601    511998    473221   \n",
       "..            ...         ...           ...      ...       ...       ...   \n",
       "736          8131         293           261     6436      6283      5334   \n",
       "737        450292       44333         43654   511732    479989    432135   \n",
       "738        101821        3034          2813   212628    200580    184976   \n",
       "739         10136         661           669    16747     14415     14234   \n",
       "740          4841         558           539    30732     27877     26737   \n",
       "\n",
       "     HWA_FEMALE  HBA_MALE  HBA_FEMALE  HIA_MALE  HIA_FEMALE  HAA_MALE  \\\n",
       "0         68742      6859        6084      3919        2825       928   \n",
       "1         78371      3221        2972      3175        2696       766   \n",
       "2        857237     19772       20345     40230       37399      7985   \n",
       "3       6257366    146293      153731    236136      222558    109856   \n",
       "4        453057     12193       12632     24010       22838      3983   \n",
       "..          ...       ...         ...       ...         ...       ...   \n",
       "736        5229       342         280       212         171        73   \n",
       "737      404972     14461       13239     26357       23936      8289   \n",
       "738      173740      9250        9020      8288        7904      1547   \n",
       "739       12376      1046         789       432         317       171   \n",
       "740       24254       482         465      1930        1650       235   \n",
       "\n",
       "     HAA_FEMALE  HNA_MALE  HNA_FEMALE  HTOM_MALE  HTOM_FEMALE  HWAC_MALE  \\\n",
       "0           706      1887        1256       3256         2795      89694   \n",
       "1           681       621         432       2520         2363      91972   \n",
       "2          8110      2509        2466      22131        21859     883360   \n",
       "3        112044     24527       24338     189983       191235    6564217   \n",
       "4          3995      1361        1342      17833        18134     489491   \n",
       "..          ...       ...         ...        ...          ...        ...   \n",
       "736          78        26          24        449          501       5741   \n",
       "737        8071      2996        2720      27494        27051     456676   \n",
       "738        1527       579         522       7988         7867     192305   \n",
       "739         139        59          60        805          734      14966   \n",
       "740         207       100          84       1248         1217      27914   \n",
       "\n",
       "     HWAC_FEMALE  HBAC_MALE  HBAC_FEMALE  HIAC_MALE  HIAC_FEMALE  HAAC_MALE  \\\n",
       "0          71081       8352         7435       5647         4238       1567   \n",
       "1          80529       4036         3703       4706         4196       1255   \n",
       "2         876841      26926        27659      51863        48682      14208   \n",
       "3        6427486     197899       207315     328419       314519     181535   \n",
       "4         469666      17631        18038      35000        34122       7870   \n",
       "..           ...        ...          ...        ...          ...        ...   \n",
       "736         5689        599          556        421          406        147   \n",
       "737       429192      23847        22228      40119        37254      17301   \n",
       "738       180958      13538        13268      12144        11647       2724   \n",
       "739        13054       1500         1168        787          672        358   \n",
       "740        25377        871          851       2697         2406        425   \n",
       "\n",
       "     HAAC_FEMALE  HNAC_MALE  HNAC_FEMALE      PRECIP  N_WET_NH4  N_WET_NO3  \\\n",
       "0           1315       2231         1588  131.225000   2.506000   2.165000   \n",
       "1           1123        831          624  151.199000   1.507000   2.241000   \n",
       "2          14387       4143         4041   34.533333   0.549667   0.827333   \n",
       "3         184522      42537        42714   58.153625   1.176000   0.892625   \n",
       "4           7946       2413         2405   55.322000   0.772000   1.045000   \n",
       "..           ...        ...          ...         ...        ...        ...   \n",
       "736          163         48           36  160.718000   2.853500   2.368500   \n",
       "737        17316       5832         5792  107.980750   0.456500   0.493750   \n",
       "738         2734        918          816  130.666000   5.162000   1.949000   \n",
       "739          287        115          142  123.584000   1.982000   1.601500   \n",
       "740          439        188          149   57.293000   1.233500   0.676875   \n",
       "\n",
       "       N_WET  N_DRY_HNO3  N_DRY_NO3  N_DRY_TNO3  N_DRY_NH4  N_DRY_NH3  \\\n",
       "0    4.67200    4.173000   0.286000    4.460000   0.398000   1.535000   \n",
       "1    3.74800    3.314000   0.077000    3.391000   0.233000   1.217000   \n",
       "2    1.37700    1.498000   0.107333    1.605667   0.113667   0.365667   \n",
       "3    2.06875    3.764625   0.248125    4.012500   0.226250   2.296750   \n",
       "4    1.81650    1.412250   0.224000    1.636250   0.175000   0.331500   \n",
       "..       ...         ...        ...         ...        ...        ...   \n",
       "736  5.22200    1.118500   0.099500    1.218000   0.133500   1.460000   \n",
       "737  0.95075    0.900000   0.040750    0.940750   0.078500   0.641750   \n",
       "738  7.11100    0.999000   0.175000    1.174000   0.175000   3.733000   \n",
       "739  3.58300    1.309000   0.082500    1.392000   0.173000   1.523000   \n",
       "740  1.91025    0.445500   0.060750    0.506250   0.078125   0.516500   \n",
       "\n",
       "     N_DRY_NH3NET  N_DRY_NOM  N_DRY_NRED  N_DRY_NOXI     N_DRY  S_WET_SO4  \\\n",
       "0        0.791000   1.932000    1.933000    6.391000  8.324000   4.921000   \n",
       "1        0.678000   1.516000    1.450000    4.907000  6.356000   4.147000   \n",
       "2        0.131667   0.253000    0.479333    1.858333  2.337667   0.823667   \n",
       "3        2.054875   0.449625    2.522625    4.462250  6.984875   0.590750   \n",
       "4        0.198750   0.282750    0.506500    1.919250  2.425500   0.842750   \n",
       "..            ...        ...         ...         ...       ...        ...   \n",
       "736      1.300500   0.468000    1.593000    1.686500  3.279500   1.647000   \n",
       "737     -0.171500   0.414000    0.720000    1.354750  2.074750   0.556250   \n",
       "738      3.415000   0.422000    3.908000    1.596000  5.504000   1.457000   \n",
       "739      1.121000   0.985500    1.696000    2.377000  4.073500   1.777000   \n",
       "740      0.282375   0.164500    0.594875    0.671000  1.265750   0.486375   \n",
       "\n",
       "        S_WET  S_DRY_SO2  S_DRY_SO4     S_DRY    NA_DRY   NA_WET    MG_DRY  \\\n",
       "0    4.921000   6.638000   0.318000  6.956000  0.196000  1.27300  0.046000   \n",
       "1    4.147000   1.446000   0.244000  1.690000  0.208000  1.44200  0.038000   \n",
       "2    0.823667   0.369667   0.104333  0.474333  0.126333  0.23300  0.035333   \n",
       "3    0.590750   0.419875   0.124625  0.544375  0.288750  0.73975  0.058000   \n",
       "4    0.842750   0.274500   0.133000  0.407500  0.095000  0.15750  0.038500   \n",
       "..        ...        ...        ...       ...       ...      ...       ...   \n",
       "736  1.647000   0.235000   0.089500  0.324000  0.149000  0.82700  0.031000   \n",
       "737  0.556250   0.208750   0.088250  0.296500  0.123250  2.19850  0.052250   \n",
       "738  1.457000   0.315000   0.056000  0.371000  0.059000  0.24900  0.044000   \n",
       "739  1.777000   0.666000   0.111000  0.777000  0.063500  0.36850  0.029000   \n",
       "740  0.486375   0.198500   0.038000  0.236625  0.035625  0.19725  0.019375   \n",
       "\n",
       "     MG_WET     K_DRY     K_WET    CA_DRY    CA_WET    CL_DRY    CL_WET  \n",
       "0    0.2230  0.060000  0.551000  0.184000  0.866000  0.106000  2.245000  \n",
       "1    0.2400  0.048000  0.526000  0.135000  1.754000  0.092000  2.448000  \n",
       "2    0.0950  0.038667  0.140667  0.269667  0.934667  0.044000  0.423667  \n",
       "3    0.1050  0.070250  0.104875  0.261250  0.467375  0.088375  1.249750  \n",
       "4    0.0865  0.048500  0.095000  0.275250  0.910750  0.048250  0.270750  \n",
       "..      ...       ...       ...       ...       ...       ...       ...  \n",
       "736  0.2350  0.035500  0.526000  0.124500  1.525000  0.142500  1.424500  \n",
       "737  0.2580  0.036500  0.171250  0.047000  0.321750  0.117000  4.055000  \n",
       "738  0.3400  0.039000  0.457000  0.220000  3.094000  0.090000  0.549000  \n",
       "739  0.1550  0.044000  0.282000  0.239500  1.209500  0.054000  0.655000  \n",
       "740  0.1000  0.027250  0.109750  0.167250  0.903125  0.030500  0.370750  \n",
       "\n",
       "[741 rows x 105 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2e7998",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:01.949987Z",
     "start_time": "2023-04-17T12:41:01.918009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>StateDesc</th>\n",
       "      <th>Year</th>\n",
       "      <th>CAN10_1</th>\n",
       "      <th>CAN11_1</th>\n",
       "      <th>CAN5_1</th>\n",
       "      <th>CAN6_1</th>\n",
       "      <th>CAN7_1</th>\n",
       "      <th>CAN8_1</th>\n",
       "      <th>CAN9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2008</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>108.950000</td>\n",
       "      <td>124.350000</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>42.100000</td>\n",
       "      <td>59.300000</td>\n",
       "      <td>12.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2009</td>\n",
       "      <td>11.625000</td>\n",
       "      <td>104.125000</td>\n",
       "      <td>123.925000</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>42.050000</td>\n",
       "      <td>58.275000</td>\n",
       "      <td>13.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.616667</td>\n",
       "      <td>99.566667</td>\n",
       "      <td>124.733333</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>41.650000</td>\n",
       "      <td>57.283333</td>\n",
       "      <td>13.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2011</td>\n",
       "      <td>11.637500</td>\n",
       "      <td>94.937500</td>\n",
       "      <td>125.225000</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>56.562500</td>\n",
       "      <td>13.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>2012</td>\n",
       "      <td>11.620000</td>\n",
       "      <td>92.220000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>41.110000</td>\n",
       "      <td>55.990000</td>\n",
       "      <td>13.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>11.080000</td>\n",
       "      <td>119.840000</td>\n",
       "      <td>123.400000</td>\n",
       "      <td>7.060000</td>\n",
       "      <td>35.360000</td>\n",
       "      <td>46.700000</td>\n",
       "      <td>24.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2016</td>\n",
       "      <td>11.212500</td>\n",
       "      <td>121.737500</td>\n",
       "      <td>123.837500</td>\n",
       "      <td>7.075000</td>\n",
       "      <td>35.450000</td>\n",
       "      <td>46.587500</td>\n",
       "      <td>25.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2017</td>\n",
       "      <td>11.416667</td>\n",
       "      <td>125.483333</td>\n",
       "      <td>124.333333</td>\n",
       "      <td>7.450000</td>\n",
       "      <td>35.633333</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>25.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2018</td>\n",
       "      <td>11.475000</td>\n",
       "      <td>128.225000</td>\n",
       "      <td>125.150000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>36.150000</td>\n",
       "      <td>46.475000</td>\n",
       "      <td>26.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>WY</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2019</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>130.300000</td>\n",
       "      <td>124.850000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>37.050000</td>\n",
       "      <td>46.700000</td>\n",
       "      <td>26.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State StateDesc  Year    CAN10_1     CAN11_1      CAN5_1    CAN6_1  \\\n",
       "0      AK    Alaska  2008  11.500000  108.950000  124.350000  7.300000   \n",
       "1      AK    Alaska  2009  11.625000  104.125000  123.925000  7.125000   \n",
       "2      AK    Alaska  2010  11.616667   99.566667  124.733333  6.833333   \n",
       "3      AK    Alaska  2011  11.637500   94.937500  125.225000  6.875000   \n",
       "4      AK    Alaska  2012  11.620000   92.220000  125.000000  6.950000   \n",
       "..    ...       ...   ...        ...         ...         ...       ...   \n",
       "619    WY   Wyoming  2015  11.080000  119.840000  123.400000  7.060000   \n",
       "620    WY   Wyoming  2016  11.212500  121.737500  123.837500  7.075000   \n",
       "621    WY   Wyoming  2017  11.416667  125.483333  124.333333  7.450000   \n",
       "622    WY   Wyoming  2018  11.475000  128.225000  125.150000  7.900000   \n",
       "623    WY   Wyoming  2019  11.600000  130.300000  124.850000  8.250000   \n",
       "\n",
       "        CAN7_1     CAN8_1     CAN9_1  \n",
       "0    42.100000  59.300000  12.700000  \n",
       "1    42.050000  58.275000  13.050000  \n",
       "2    41.650000  57.283333  13.466667  \n",
       "3    41.350000  56.562500  13.637500  \n",
       "4    41.110000  55.990000  13.840000  \n",
       "..         ...        ...        ...  \n",
       "619  35.360000  46.700000  24.890000  \n",
       "620  35.450000  46.587500  25.200000  \n",
       "621  35.633333  46.333333  25.700000  \n",
       "622  36.150000  46.475000  26.325000  \n",
       "623  37.050000  46.700000  26.450000  \n",
       "\n",
       "[624 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disease_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04031108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:02.406112Z",
     "start_time": "2023-04-17T12:41:02.381475Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(feature_df, disease_df, on=['Year', 'State'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6b6c1",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d91f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        corr, p_value = pearsonr(corr_matrix.iloc[:, i], corr_matrix.iloc[:, j])\n",
    "        if p_value < alpha and corr_matrix.columns[i].startswith('CAN5_1'):\n",
    "            print(f\"Correlation between {corr_matrix.columns[i]} and {corr_matrix.columns[j]} is significant (p-value: {p_value:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9454f3e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f24e51",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67a74d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:05.513569Z",
     "start_time": "2023-04-17T12:41:05.499530Z"
    }
   },
   "outputs": [],
   "source": [
    "state_list = df['State'].unique()\n",
    "seq_length = 2\n",
    "seq_length_plus_diff = seq_length+1\n",
    "\n",
    "df = df.drop(['StateDesc'], axis=1)\n",
    "df = df.sort_values(by='Year')\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98314c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:05.872529Z",
     "start_time": "2023-04-17T12:41:05.849530Z"
    }
   },
   "outputs": [],
   "source": [
    "min_year_val = 2016\n",
    "min_year_test = 2019\n",
    "\n",
    "train_data = df[df['Year'] < min_year_val].copy()\n",
    "val_data = df[(df['Year'] >= min_year_val-seq_length_plus_diff) & (df['Year'] < min_year_test)].copy()\n",
    "test_data = df[df['Year'] >= min_year_test-seq_length_plus_diff].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841eecf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:06.357323Z",
     "start_time": "2023-04-17T12:41:06.334551Z"
    }
   },
   "outputs": [],
   "source": [
    "val_data_compare_acc = val_data[(val_data['Year'] >= min_year_val) & (val_data['Year'] < min_year_test) ]\n",
    "test_data_compare_acc = test_data[test_data['Year'] >= min_year_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb674402",
   "metadata": {},
   "source": [
    "# Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fe63a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:07.301572Z",
     "start_time": "2023-04-17T12:41:07.285471Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_diff(df):\n",
    "    \n",
    "    Base_Year = np.min(df['Year'])\n",
    "    \n",
    "    Base_row = df[df['Year'] == Base_Year]\n",
    "    \n",
    "    df_diff = pd.DataFrame()\n",
    "\n",
    "    for state in state_list:\n",
    "\n",
    "        df_state = df[df['State'] == state]\n",
    "        df_state_diff = df_state.iloc[:,2:].diff().dropna()\n",
    "        df_state = pd.concat([df_state[['Year', 'State']] , df_state_diff ], axis=1)\n",
    "        df_state.dropna(inplace=True)\n",
    "\n",
    "        df_diff = pd.concat([df_diff, df_state], axis=0)\n",
    "    \n",
    "    df['Year'] = df['Year'] + 1\n",
    "    base_df = df \n",
    "    df = df_diff\n",
    "    \n",
    "    return base_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "321f8b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:08.281225Z",
     "start_time": "2023-04-17T12:41:07.816047Z"
    }
   },
   "outputs": [],
   "source": [
    "base_df_train, train_data = df_diff(train_data)\n",
    "base_df_val,val_data = df_diff(val_data)\n",
    "base_df_test,test_data = df_diff(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8571309",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d254ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:08.780900Z",
     "start_time": "2023-04-17T12:41:08.761864Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler_train = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_val = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler_test = MinMaxScaler(feature_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e31f5882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:09.347673Z",
     "start_time": "2023-04-17T12:41:09.262914Z"
    }
   },
   "outputs": [],
   "source": [
    "#columns_to_normalize = list(df.columns[2:-8])\n",
    "\n",
    "# To standardize the target columns as well\n",
    "\n",
    "columns_to_normalize = list(df.columns[2:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data[columns_to_normalize] = scaler_train.fit_transform(train_data[columns_to_normalize])\n",
    "\n",
    "val_data[columns_to_normalize] = scaler_val.fit_transform(val_data[columns_to_normalize])\n",
    "\n",
    "test_data[columns_to_normalize] = scaler_test.fit_transform(test_data[columns_to_normalize])\n",
    "\n",
    "\n",
    "df_cols = list(df.columns)\n",
    "input_cols = [c for c in df_cols if c not in ['Year','State','StateDesc','CAN10_1','CAN11_1','CAN5_1','CAN6_1','CAN7_1','CAN8_1','CAN9_1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290affbc",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6fa603",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:13.777561Z",
     "start_time": "2023-04-17T12:41:10.285121Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import tensorflow as tf\n",
    "from keras.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f795a45",
   "metadata": {},
   "source": [
    "For adding the features from previous Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be3975b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:15.748803Z",
     "start_time": "2023-04-17T12:41:15.732798Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length,target_col):\n",
    "    \n",
    "    df_cols = list(df.columns)\n",
    "    \n",
    "    output_cols = [target_col]\n",
    "\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data.loc[i-seq_length:i, input_cols].values)\n",
    "        y.append(data.loc[i, output_cols])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X = X.astype('float32')\n",
    "    y = y.astype('float32')\n",
    "    \n",
    "    X = tf.convert_to_tensor(X)\n",
    "    y = tf.convert_to_tensor(y)\n",
    "    \n",
    "\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349892d4",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba30520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:17.006698Z",
     "start_time": "2023-04-17T12:41:16.991698Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that creates the LSTM model\n",
    "\n",
    "def create_model(num_layers, num_nodes, input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_nodes, input_shape=input_shape, activation='relu'))\n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dense(num_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d88f31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T13:54:56.938525Z",
     "start_time": "2023-04-16T13:54:56.919678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Takes about 20 minutes\n",
    "# Test with one state and one type of cancer\n",
    "\n",
    "# state = 'WY'\n",
    "# target_col = 'CAN10_1'\n",
    "# state_train_df = train_data[train_data['State'] == state]\n",
    "# state_train_df = state_train_df.sort_values(by='Year')\n",
    "# state_train_df = state_train_df.reset_index(drop=True)\n",
    "\n",
    "# state_val_df = val_data[val_data['State'] == state]\n",
    "# state_val_df = state_val_df.sort_values(by='Year')\n",
    "# state_val_df = state_val_df.reset_index(drop=True)\n",
    "\n",
    "# state_test_df = test_data[test_data['State'] == state]\n",
    "# state_test_df = state_test_df.sort_values(by='Year')\n",
    "# state_test_df = state_test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, y_train = create_sequences(state_train_df, seq_length,target_col)\n",
    "# X_val, y_val = create_sequences(state_val_df, seq_length,target_col)\n",
    "# X_test, y_test = create_sequences(state_test_df, seq_length,target_col)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Define the hyperparameters to tune\n",
    "# param_grid = {\n",
    "#     'num_layers': np.array([1, 2, 3]),\n",
    "#     'num_nodes': np.array([32, 64, 128]),\n",
    "#     'epochs': np.array([50, 100, 200]),\n",
    "#     'batch_size': np.array([1, 16, 32])\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Create the KerasRegressor object\n",
    "# regressor = KerasRegressor(build_fn=create_model, input_shape=input_shape)\n",
    "\n",
    "\n",
    "# X_train_numpy = X_train.numpy()\n",
    "# y_train_numpy = y_train.numpy()\n",
    "# X_val_numpy = X_val.numpy()\n",
    "# y_val_numpy = y_val.numpy()\n",
    "# X_test_numpy = X_test.numpy()\n",
    "# y_test_numpy = y_test.numpy()\n",
    "\n",
    "# # Use GridSearchCV to perform the grid search\n",
    "# tscv = TimeSeriesSplit(n_splits=3)\n",
    "# grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=tscv)\n",
    "# grid_search.fit(X_train_numpy, y_train_numpy, validation_data=(X_val_numpy, y_val_numpy),verbose=0)\n",
    "\n",
    "# # Print the best hyperparameters and the corresponding mean squared error\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"MSE: \", abs(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a07c96a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:20.510984Z",
     "start_time": "2023-04-17T12:41:19.065336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model with the best hyperparameters\n",
    "\n",
    "# best_num_layers = grid_search.best_params_['num_layers']\n",
    "# best_num_nodes = grid_search.best_params_['num_nodes']\n",
    "# best_epochs = grid_search.best_params_['epochs']\n",
    "# best_batch_size = grid_search.best_params_['batch_size']\n",
    "\n",
    "best_num_layers = 1\n",
    "best_num_nodes = 32\n",
    "best_epochs = 100\n",
    "best_batch_size = 32\n",
    "\n",
    "num_features = len(input_cols)\n",
    "input_shape = (seq_length+1, num_features)\n",
    "\n",
    "\n",
    "final_model = create_model(num_layers=best_num_layers, num_nodes=best_num_nodes, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345ca8a",
   "metadata": {},
   "source": [
    "Design the best model based on parameter tuning.\n",
    "\n",
    "For each state and cancer type, fit the model and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad21b76f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:21.455632Z",
     "start_time": "2023-04-17T12:41:21.450630Z"
    }
   },
   "outputs": [],
   "source": [
    "target_cols = ['CAN10_1','CAN11_1','CAN5_1','CAN6_1','CAN7_1','CAN8_1','CAN9_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ed48b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T17:48:45.685155Z",
     "start_time": "2023-04-16T17:48:44.883042Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "\n",
    "for state in state_list:\n",
    "    # Subset the data for the current state\n",
    "\n",
    "    for target_col in target_cols:\n",
    "        state_preds = {}\n",
    "        \n",
    "        state_train_df = train_data[train_data['State'] == state]\n",
    "        state_train_df = state_train_df.sort_values(by='Year')\n",
    "        state_train_df = state_train_df.reset_index(drop=True)\n",
    "\n",
    "        state_val_df = val_data[val_data['State'] == state]\n",
    "        state_val_df = state_val_df.sort_values(by='Year')\n",
    "        state_val_df = state_val_df.reset_index(drop=True)\n",
    "\n",
    "        state_test_df = test_data[test_data['State'] == state]\n",
    "        state_test_df = state_test_df.sort_values(by='Year')\n",
    "        state_test_df = state_test_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "        X_train, y_train = create_sequences(state_train_df, seq_length,target_col)\n",
    "        X_val, y_val = create_sequences(state_val_df, seq_length,target_col)\n",
    "        X_test, y_test = create_sequences(state_test_df, seq_length,target_col)\n",
    "        \n",
    "        \n",
    "        X_train_numpy = X_train.numpy()\n",
    "        y_train_numpy = y_train.numpy()\n",
    "        X_val_numpy = X_val.numpy()\n",
    "        y_val_numpy = y_val.numpy()\n",
    "        X_test_numpy = X_test.numpy()\n",
    "        y_test_numpy = y_test.numpy()\n",
    "\n",
    "\n",
    "        # Train the final model on the entire training dataset\n",
    "        final_model.fit(X_train_numpy, y_train_numpy, epochs = best_epochs, batch_size=best_batch_size, verbose=0)\n",
    "        \n",
    "        y_pred = final_model.predict(X_val_numpy)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # Create a dict for creating overview_df with results\n",
    "        state_preds['State'] = state\n",
    "        state_preds['Target'] = target_col\n",
    "        state_preds['Year'] = [min(state_val_df['Year']) + i + seq_length for i in range(len(y_val_numpy))]\n",
    "        state_preds['Predicted_value'] = pd.Series(y_pred.reshape(-1).tolist())\n",
    "        state_preds['Actual_value'] = pd.Series(y_val_numpy.reshape(-1).tolist())\n",
    "        state_preds['Accuracy'] = pd.Series([mean_squared_error([y_val_numpy[i]], [y_pred[i]]) for i in range(len(y_val_numpy))])\n",
    "        preds_list.append(state_preds)\n",
    "\n",
    "\n",
    "# Create a df to show results\n",
    "overview_df = pd.DataFrame(preds_list).explode(['Year','Predicted_value', 'Actual_value', 'Accuracy'])\n",
    "overview_df = overview_df.reset_index(drop=True)\n",
    "\n",
    "# # Save overview_df\n",
    "# with open('./Data/Pickle Files/overview_df.pickle', 'wb') as f:\n",
    "#     pickle.dump(overview_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# pivot overview df to be used in our prediction df\n",
    "pivot_df = pd.pivot_table(overview_df, values='Predicted_value', index=['State', 'Year'], columns=['Target'])\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "# create prediction df\n",
    "pred_val_df = pd.merge(val_data.iloc[:, :-7], pivot_df, on=['Year', 'State'])\n",
    "\n",
    "# # Save pred_val_df\n",
    "# with open(path + 'pred_val_df.pickle', 'wb') as f:\n",
    "#     pickle.dump(pred_val_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d7280",
   "metadata": {},
   "source": [
    "## Inverse Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ef1705c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:27.159732Z",
     "start_time": "2023-04-17T12:41:27.139486Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path+'pred_val_df.pickle', 'rb') as f:\n",
    "    pred_val_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17f8cfb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:27.596184Z",
     "start_time": "2023-04-17T12:41:27.555183Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_val_df[columns_to_normalize] = scaler_val.inverse_transform(pred_val_df[columns_to_normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2ed632",
   "metadata": {},
   "source": [
    "# Inverse Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56883eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:28.583872Z",
     "start_time": "2023-04-17T12:41:28.558211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_df_val_filtered = base_df_val[(base_df_val['Year'] >= np.min(base_df_val['Year'] ) + seq_length) & (base_df_val['Year']< np.max(base_df_val['Year'] ) )].sort_values(by=['State','Year'])\n",
    "base_df_val_filtered = base_df_val_filtered.reset_index(drop=True)\n",
    "\n",
    "pred_val_df = pred_val_df.sort_values(by=['State','Year'])\n",
    "pred_val_df = pred_val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3042b271",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:30.215974Z",
     "start_time": "2023-04-17T12:41:30.193211Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_val_df_inv_diff = base_df_val_filtered.iloc[:,2:].add(pred_val_df.iloc[:,2:])\n",
    "pred_val_df = pd.concat([pred_val_df[['Year', 'State']] , pred_val_df_inv_diff ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b84dd3",
   "metadata": {},
   "source": [
    "Compare pred_val_df with val_data_compare_acc (2016-2018) and create a dataset with columns: State, Cancer Type, MSE\n",
    "Then get the dataset from Baseline and compare MSE s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9871087",
   "metadata": {},
   "source": [
    "### Comparison with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33955a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:44.670527Z",
     "start_time": "2023-04-17T12:41:44.648525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year</th>\n",
       "      <th>Predicted_value</th>\n",
       "      <th>Actual_value</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.071163</td>\n",
       "      <td>-0.350649</td>\n",
       "      <td>0.177925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>-0.593074</td>\n",
       "      <td>0.555826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>-0.744589</td>\n",
       "      <td>0.774205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>-0.031864</td>\n",
       "      <td>0.186529</td>\n",
       "      <td>0.047695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>-0.232868</td>\n",
       "      <td>0.408981</td>\n",
       "      <td>0.41197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>WY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>-0.145585</td>\n",
       "      <td>0.169071</td>\n",
       "      <td>0.099008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>WY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.145585</td>\n",
       "      <td>0.549679</td>\n",
       "      <td>0.483393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>WY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>-0.28312</td>\n",
       "      <td>-0.405927</td>\n",
       "      <td>0.015082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>WY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>-0.28312</td>\n",
       "      <td>-0.248794</td>\n",
       "      <td>0.001178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>WY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>-0.28312</td>\n",
       "      <td>-0.145417</td>\n",
       "      <td>0.018962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>819 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State   Target  Year Predicted_value Actual_value  Accuracy\n",
       "0      AL  CAN10_1  2016        0.071163    -0.350649  0.177925\n",
       "1      AL  CAN10_1  2017        0.152464    -0.593074  0.555826\n",
       "2      AL  CAN10_1  2018          0.1353    -0.744589  0.774205\n",
       "3      AL  CAN11_1  2016       -0.031864     0.186529  0.047695\n",
       "4      AL  CAN11_1  2017       -0.232868     0.408981   0.41197\n",
       "..    ...      ...   ...             ...          ...       ...\n",
       "814    WY   CAN8_1  2017       -0.145585     0.169071  0.099008\n",
       "815    WY   CAN8_1  2018       -0.145585     0.549679  0.483393\n",
       "816    WY   CAN9_1  2016        -0.28312    -0.405927  0.015082\n",
       "817    WY   CAN9_1  2017        -0.28312    -0.248794  0.001178\n",
       "818    WY   CAN9_1  2018        -0.28312    -0.145417  0.018962\n",
       "\n",
       "[819 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./Data/Pickle Files/overview_df.pickle', 'rb') as f:\n",
    "    overview_df = pickle.load(f)\n",
    "    \n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c139927f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:45.862566Z",
     "start_time": "2023-04-17T12:41:45.834636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.303772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.540732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.538895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.028863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.014464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.004266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.084939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.153605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.128347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.345732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.375458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.275313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.030926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.002862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.033693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.094177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.077617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.07773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.24785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.004956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.011137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.020712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.026816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.208533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.361264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.023344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.009466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.080616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.109089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.218219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.085912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.098377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.059678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.075091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.123821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.094565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.303057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.296699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.341181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.322849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.351957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.178902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.151737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.304455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.198212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.083704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.019053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.592049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.54421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.322909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.021411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.045151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.352228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.082948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.293095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.357491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.335126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.097589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    State   Target  Year  Accuracy\n",
       "63     CA  CAN10_1  2016  0.303772\n",
       "64     CA  CAN10_1  2017  0.540732\n",
       "65     CA  CAN10_1  2018  0.538895\n",
       "66     CA  CAN11_1  2016  0.028863\n",
       "67     CA  CAN11_1  2017  0.014464\n",
       "68     CA  CAN11_1  2018  0.004266\n",
       "69     CA   CAN5_1  2016  0.084939\n",
       "70     CA   CAN5_1  2017  0.153605\n",
       "71     CA   CAN5_1  2018  0.128347\n",
       "72     CA   CAN6_1  2016  0.345732\n",
       "73     CA   CAN6_1  2017  0.375458\n",
       "74     CA   CAN6_1  2018  0.275313\n",
       "75     CA   CAN7_1  2016  0.030926\n",
       "76     CA   CAN7_1  2017  0.002862\n",
       "77     CA   CAN7_1  2018  0.033693\n",
       "78     CA   CAN8_1  2016  0.094177\n",
       "79     CA   CAN8_1  2017  0.000389\n",
       "80     CA   CAN8_1  2018  0.000014\n",
       "81     CA   CAN9_1  2016  0.077617\n",
       "82     CA   CAN9_1  2017   0.07773\n",
       "83     CA   CAN9_1  2018   0.24785\n",
       "525    NY  CAN10_1  2016  0.004956\n",
       "526    NY  CAN10_1  2017  0.011137\n",
       "527    NY  CAN10_1  2018  0.020712\n",
       "528    NY  CAN11_1  2016  0.026816\n",
       "529    NY  CAN11_1  2017  0.208533\n",
       "530    NY  CAN11_1  2018  0.361264\n",
       "531    NY   CAN5_1  2016  0.000382\n",
       "532    NY   CAN5_1  2017  0.023344\n",
       "533    NY   CAN5_1  2018  0.009466\n",
       "534    NY   CAN6_1  2016  0.080616\n",
       "535    NY   CAN6_1  2017  0.109089\n",
       "536    NY   CAN6_1  2018  0.218219\n",
       "537    NY   CAN7_1  2016  0.085912\n",
       "538    NY   CAN7_1  2017  0.098377\n",
       "539    NY   CAN7_1  2018  0.059678\n",
       "540    NY   CAN8_1  2016  0.075091\n",
       "541    NY   CAN8_1  2017  0.123821\n",
       "542    NY   CAN8_1  2018  0.094565\n",
       "543    NY   CAN9_1  2016  0.303057\n",
       "544    NY   CAN9_1  2017  0.296699\n",
       "545    NY   CAN9_1  2018  0.341181\n",
       "651    TX  CAN10_1  2016  0.322849\n",
       "652    TX  CAN10_1  2017  0.351957\n",
       "653    TX  CAN10_1  2018  0.178902\n",
       "654    TX  CAN11_1  2016  0.151737\n",
       "655    TX  CAN11_1  2017  0.000006\n",
       "656    TX  CAN11_1  2018  0.304455\n",
       "657    TX   CAN5_1  2016  0.198212\n",
       "658    TX   CAN5_1  2017  0.083704\n",
       "659    TX   CAN5_1  2018  0.019053\n",
       "660    TX   CAN6_1  2016  0.592049\n",
       "661    TX   CAN6_1  2017   0.54421\n",
       "662    TX   CAN6_1  2018  0.322909\n",
       "663    TX   CAN7_1  2016  0.021411\n",
       "664    TX   CAN7_1  2017  0.000206\n",
       "665    TX   CAN7_1  2018  0.045151\n",
       "666    TX   CAN8_1  2016  0.352228\n",
       "667    TX   CAN8_1  2017  0.082948\n",
       "668    TX   CAN8_1  2018  0.293095\n",
       "669    TX   CAN9_1  2016  0.357491\n",
       "670    TX   CAN9_1  2017  0.335126\n",
       "671    TX   CAN9_1  2018  0.097589"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_df = overview_df.loc[:, ['State', 'Target', 'Year', 'Accuracy']][((overview_df['State'] == 'CA') | (overview_df['State'] == 'NY') | (overview_df['State'] == 'TX'))]\n",
    "overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a7384e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:46.739280Z",
     "start_time": "2023-04-17T12:41:46.716258Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.340938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.772645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>5.048657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.150292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.016945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.015169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.001556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.011806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.035250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.092992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.016103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.008967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.276126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.152902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.276970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.025292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.037411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.113815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.018787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.034256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.243450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.278053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.820644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>71.902691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.918952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.687348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>18.565684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.004812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.034124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.004389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.018561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.093385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.344223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.002991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.031412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.127402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.009620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.001315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.927737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>10.982685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>63.258346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.569354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.177876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.028078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.002071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.004008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.105609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.397753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.269079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.300338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2.094331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.461267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.213906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.071111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Target  Year   Accuracy\n",
       "0     CA  CAN10_1  2016   0.000830\n",
       "1     CA  CAN10_1  2017   0.000113\n",
       "2     CA  CAN10_1  2018   0.000064\n",
       "3     CA  CAN11_1  2016   0.340938\n",
       "4     CA  CAN11_1  2017   0.772645\n",
       "5     CA  CAN11_1  2018   5.048657\n",
       "6     CA   CAN5_1  2016   0.150292\n",
       "7     CA   CAN5_1  2017   0.016945\n",
       "8     CA   CAN5_1  2018   0.015169\n",
       "9     CA   CAN6_1  2016   0.001556\n",
       "10    CA   CAN6_1  2017   0.011806\n",
       "11    CA   CAN6_1  2018   0.035250\n",
       "12    CA   CAN7_1  2016   0.092992\n",
       "13    CA   CAN7_1  2017   0.016103\n",
       "14    CA   CAN7_1  2018   0.008967\n",
       "15    CA   CAN8_1  2016   0.276126\n",
       "16    CA   CAN8_1  2017   0.152902\n",
       "17    CA   CAN8_1  2018   1.276970\n",
       "18    CA   CAN9_1  2016   0.025292\n",
       "19    CA   CAN9_1  2017   0.037411\n",
       "20    CA   CAN9_1  2018   0.113815\n",
       "21    NY  CAN10_1  2016   0.018787\n",
       "22    NY  CAN10_1  2017   0.034256\n",
       "23    NY  CAN10_1  2018   0.243450\n",
       "24    NY  CAN11_1  2016   1.278053\n",
       "25    NY  CAN11_1  2017  12.820644\n",
       "26    NY  CAN11_1  2018  71.902691\n",
       "27    NY   CAN5_1  2016   0.918952\n",
       "28    NY   CAN5_1  2017   2.687348\n",
       "29    NY   CAN5_1  2018  18.565684\n",
       "30    NY   CAN6_1  2016   0.005133\n",
       "31    NY   CAN6_1  2017   0.001837\n",
       "32    NY   CAN6_1  2018   0.004812\n",
       "33    NY   CAN7_1  2016   0.034124\n",
       "34    NY   CAN7_1  2017   0.004389\n",
       "35    NY   CAN7_1  2018   0.001011\n",
       "36    NY   CAN8_1  2016   0.018561\n",
       "37    NY   CAN8_1  2017   0.093385\n",
       "38    NY   CAN8_1  2018   0.344223\n",
       "39    NY   CAN9_1  2016   0.002991\n",
       "40    NY   CAN9_1  2017   0.031412\n",
       "41    NY   CAN9_1  2018   0.127402\n",
       "42    TX  CAN10_1  2016   0.009620\n",
       "43    TX  CAN10_1  2017   0.001315\n",
       "44    TX  CAN10_1  2018   0.002468\n",
       "45    TX  CAN11_1  2016   1.927737\n",
       "46    TX  CAN11_1  2017  10.982685\n",
       "47    TX  CAN11_1  2018  63.258346\n",
       "48    TX   CAN5_1  2016   1.569354\n",
       "49    TX   CAN5_1  2017   0.177876\n",
       "50    TX   CAN5_1  2018   0.028078\n",
       "51    TX   CAN6_1  2016   0.002071\n",
       "52    TX   CAN6_1  2017   0.000422\n",
       "53    TX   CAN6_1  2018   0.000065\n",
       "54    TX   CAN7_1  2016   0.004008\n",
       "55    TX   CAN7_1  2017   0.105609\n",
       "56    TX   CAN7_1  2018   0.397753\n",
       "57    TX   CAN8_1  2016   0.269079\n",
       "58    TX   CAN8_1  2017   0.300338\n",
       "59    TX   CAN8_1  2018   2.094331\n",
       "60    TX   CAN9_1  2016   0.461267\n",
       "61    TX   CAN9_1  2017   0.213906\n",
       "62    TX   CAN9_1  2018   0.071111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df = pd.read_csv('./Data/Pickle Files/BasisModelAcc.csv')\n",
    "baseline_df = baseline_df.rename(columns={'Cancer':'Target'})\n",
    "baseline_df['State'] = baseline_df['State'].replace({'CAL':'CA', 'TEX':'TX'})\n",
    "baseline_df = baseline_df[['State', 'Target', 'Year', 'Accuracy']]\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2da7f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:41:47.634066Z",
     "start_time": "2023-04-17T12:41:47.603036Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Target</th>\n",
       "      <th>Year</th>\n",
       "      <th>Accuracy_pred</th>\n",
       "      <th>Accuracy_base</th>\n",
       "      <th>Accuracy_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.303772</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>0.302941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.540732</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.540619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.538895</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.538831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.028863</td>\n",
       "      <td>0.340938</td>\n",
       "      <td>-0.312075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.014464</td>\n",
       "      <td>0.772645</td>\n",
       "      <td>-0.758181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>5.048657</td>\n",
       "      <td>-5.044391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.084939</td>\n",
       "      <td>0.150292</td>\n",
       "      <td>-0.065353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.153605</td>\n",
       "      <td>0.016945</td>\n",
       "      <td>0.13666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.128347</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>0.113178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.345732</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.344176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.375458</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.363651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.275313</td>\n",
       "      <td>0.035250</td>\n",
       "      <td>0.240063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.030926</td>\n",
       "      <td>0.092992</td>\n",
       "      <td>-0.062066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>0.016103</td>\n",
       "      <td>-0.013241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.033693</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.024726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.094177</td>\n",
       "      <td>0.276126</td>\n",
       "      <td>-0.18195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.152902</td>\n",
       "      <td>-0.152513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.276970</td>\n",
       "      <td>-1.276956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.077617</td>\n",
       "      <td>0.025292</td>\n",
       "      <td>0.052324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.07773</td>\n",
       "      <td>0.037411</td>\n",
       "      <td>0.040319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.24785</td>\n",
       "      <td>0.113815</td>\n",
       "      <td>0.134036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.018787</td>\n",
       "      <td>-0.013831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>0.034256</td>\n",
       "      <td>-0.023119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.020712</td>\n",
       "      <td>0.243450</td>\n",
       "      <td>-0.222738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.026816</td>\n",
       "      <td>1.278053</td>\n",
       "      <td>-1.251237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.208533</td>\n",
       "      <td>12.820644</td>\n",
       "      <td>-12.612111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.361264</td>\n",
       "      <td>71.902691</td>\n",
       "      <td>-71.541427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.918952</td>\n",
       "      <td>-0.918569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.023344</td>\n",
       "      <td>2.687348</td>\n",
       "      <td>-2.664004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>18.565684</td>\n",
       "      <td>-18.556218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.080616</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.075483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.109089</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.107251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.218219</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.213407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.085912</td>\n",
       "      <td>0.034124</td>\n",
       "      <td>0.051787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.098377</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.093987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.059678</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.058667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.075091</td>\n",
       "      <td>0.018561</td>\n",
       "      <td>0.05653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.123821</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>0.030436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.094565</td>\n",
       "      <td>0.344223</td>\n",
       "      <td>-0.249658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.303057</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.300066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.296699</td>\n",
       "      <td>0.031412</td>\n",
       "      <td>0.265287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NY</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.341181</td>\n",
       "      <td>0.127402</td>\n",
       "      <td>0.213779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.322849</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.31323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.351957</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.350642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN10_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.178902</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>0.176434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.151737</td>\n",
       "      <td>1.927737</td>\n",
       "      <td>-1.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>10.982685</td>\n",
       "      <td>-10.982679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN11_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.304455</td>\n",
       "      <td>63.258346</td>\n",
       "      <td>-62.953891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.198212</td>\n",
       "      <td>1.569354</td>\n",
       "      <td>-1.371141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.083704</td>\n",
       "      <td>0.177876</td>\n",
       "      <td>-0.094172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN5_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.019053</td>\n",
       "      <td>0.028078</td>\n",
       "      <td>-0.009025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.592049</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.589978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.54421</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.543788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN6_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.322909</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.322844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.021411</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.017403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.105609</td>\n",
       "      <td>-0.105403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN7_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.045151</td>\n",
       "      <td>0.397753</td>\n",
       "      <td>-0.352601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.352228</td>\n",
       "      <td>0.269079</td>\n",
       "      <td>0.083149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.082948</td>\n",
       "      <td>0.300338</td>\n",
       "      <td>-0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN8_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.293095</td>\n",
       "      <td>2.094331</td>\n",
       "      <td>-1.801236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.357491</td>\n",
       "      <td>0.461267</td>\n",
       "      <td>-0.103776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.335126</td>\n",
       "      <td>0.213906</td>\n",
       "      <td>0.12122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TX</td>\n",
       "      <td>CAN9_1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.097589</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>0.026478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State   Target  Year Accuracy_pred  Accuracy_base Accuracy_diff\n",
       "0     CA  CAN10_1  2016      0.303772       0.000830      0.302941\n",
       "1     CA  CAN10_1  2017      0.540732       0.000113      0.540619\n",
       "2     CA  CAN10_1  2018      0.538895       0.000064      0.538831\n",
       "3     CA  CAN11_1  2016      0.028863       0.340938     -0.312075\n",
       "4     CA  CAN11_1  2017      0.014464       0.772645     -0.758181\n",
       "5     CA  CAN11_1  2018      0.004266       5.048657     -5.044391\n",
       "6     CA   CAN5_1  2016      0.084939       0.150292     -0.065353\n",
       "7     CA   CAN5_1  2017      0.153605       0.016945       0.13666\n",
       "8     CA   CAN5_1  2018      0.128347       0.015169      0.113178\n",
       "9     CA   CAN6_1  2016      0.345732       0.001556      0.344176\n",
       "10    CA   CAN6_1  2017      0.375458       0.011806      0.363651\n",
       "11    CA   CAN6_1  2018      0.275313       0.035250      0.240063\n",
       "12    CA   CAN7_1  2016      0.030926       0.092992     -0.062066\n",
       "13    CA   CAN7_1  2017      0.002862       0.016103     -0.013241\n",
       "14    CA   CAN7_1  2018      0.033693       0.008967      0.024726\n",
       "15    CA   CAN8_1  2016      0.094177       0.276126      -0.18195\n",
       "16    CA   CAN8_1  2017      0.000389       0.152902     -0.152513\n",
       "17    CA   CAN8_1  2018      0.000014       1.276970     -1.276956\n",
       "18    CA   CAN9_1  2016      0.077617       0.025292      0.052324\n",
       "19    CA   CAN9_1  2017       0.07773       0.037411      0.040319\n",
       "20    CA   CAN9_1  2018       0.24785       0.113815      0.134036\n",
       "21    NY  CAN10_1  2016      0.004956       0.018787     -0.013831\n",
       "22    NY  CAN10_1  2017      0.011137       0.034256     -0.023119\n",
       "23    NY  CAN10_1  2018      0.020712       0.243450     -0.222738\n",
       "24    NY  CAN11_1  2016      0.026816       1.278053     -1.251237\n",
       "25    NY  CAN11_1  2017      0.208533      12.820644    -12.612111\n",
       "26    NY  CAN11_1  2018      0.361264      71.902691    -71.541427\n",
       "27    NY   CAN5_1  2016      0.000382       0.918952     -0.918569\n",
       "28    NY   CAN5_1  2017      0.023344       2.687348     -2.664004\n",
       "29    NY   CAN5_1  2018      0.009466      18.565684    -18.556218\n",
       "30    NY   CAN6_1  2016      0.080616       0.005133      0.075483\n",
       "31    NY   CAN6_1  2017      0.109089       0.001837      0.107251\n",
       "32    NY   CAN6_1  2018      0.218219       0.004812      0.213407\n",
       "33    NY   CAN7_1  2016      0.085912       0.034124      0.051787\n",
       "34    NY   CAN7_1  2017      0.098377       0.004389      0.093987\n",
       "35    NY   CAN7_1  2018      0.059678       0.001011      0.058667\n",
       "36    NY   CAN8_1  2016      0.075091       0.018561       0.05653\n",
       "37    NY   CAN8_1  2017      0.123821       0.093385      0.030436\n",
       "38    NY   CAN8_1  2018      0.094565       0.344223     -0.249658\n",
       "39    NY   CAN9_1  2016      0.303057       0.002991      0.300066\n",
       "40    NY   CAN9_1  2017      0.296699       0.031412      0.265287\n",
       "41    NY   CAN9_1  2018      0.341181       0.127402      0.213779\n",
       "42    TX  CAN10_1  2016      0.322849       0.009620       0.31323\n",
       "43    TX  CAN10_1  2017      0.351957       0.001315      0.350642\n",
       "44    TX  CAN10_1  2018      0.178902       0.002468      0.176434\n",
       "45    TX  CAN11_1  2016      0.151737       1.927737        -1.776\n",
       "46    TX  CAN11_1  2017      0.000006      10.982685    -10.982679\n",
       "47    TX  CAN11_1  2018      0.304455      63.258346    -62.953891\n",
       "48    TX   CAN5_1  2016      0.198212       1.569354     -1.371141\n",
       "49    TX   CAN5_1  2017      0.083704       0.177876     -0.094172\n",
       "50    TX   CAN5_1  2018      0.019053       0.028078     -0.009025\n",
       "51    TX   CAN6_1  2016      0.592049       0.002071      0.589978\n",
       "52    TX   CAN6_1  2017       0.54421       0.000422      0.543788\n",
       "53    TX   CAN6_1  2018      0.322909       0.000065      0.322844\n",
       "54    TX   CAN7_1  2016      0.021411       0.004008      0.017403\n",
       "55    TX   CAN7_1  2017      0.000206       0.105609     -0.105403\n",
       "56    TX   CAN7_1  2018      0.045151       0.397753     -0.352601\n",
       "57    TX   CAN8_1  2016      0.352228       0.269079      0.083149\n",
       "58    TX   CAN8_1  2017      0.082948       0.300338     -0.217391\n",
       "59    TX   CAN8_1  2018      0.293095       2.094331     -1.801236\n",
       "60    TX   CAN9_1  2016      0.357491       0.461267     -0.103776\n",
       "61    TX   CAN9_1  2017      0.335126       0.213906       0.12122\n",
       "62    TX   CAN9_1  2018      0.097589       0.071111      0.026478"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the dataframes on 'State', 'Target', and 'Year'\n",
    "merged_df = pd.merge(overview_df, baseline_df, on=['State', 'Target', 'Year'], suffixes=('_pred', '_base'))\n",
    "\n",
    "# compute the difference in accuracy\n",
    "merged_df['Accuracy_diff'] = merged_df['Accuracy_pred'] - merged_df['Accuracy_base']\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b922b2",
   "metadata": {},
   "source": [
    "## Forecasting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9510ed3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T13:16:16.144215Z",
     "start_time": "2023-04-17T13:16:13.217278Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: Tax, ARIMA Model: (1, 0, 1)\n",
      "Column: TOT_POP, ARIMA Model: (0, 1, 1)\n",
      "Column: TOT_MALE, ARIMA Model: (0, 1, 0)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m row_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Fit an ARIMA model using the auto_arima function\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mauto_arima\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuppress_warnings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ARIMA Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39morder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m forecast \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(n_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\auto.py:701\u001b[0m, in \u001b[0;36mauto_arima\u001b[1;34m(y, X, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;66;03m# init the stepwise model wrapper\u001b[39;00m\n\u001b[0;32m    670\u001b[0m     search \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39m_StepwiseFitWrapper(\n\u001b[0;32m    671\u001b[0m         y,\n\u001b[0;32m    672\u001b[0m         X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    698\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msarimax_kwargs,\n\u001b[0;32m    699\u001b[0m     )\n\u001b[1;32m--> 701\u001b[0m sorted_res \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _return_wrapper(sorted_res, return_valid_fits, start, trace)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:288\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper.solve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming stepwise search to minimize \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minformation_criterion)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# fit a baseline p, d, q model\u001b[39;00m\n\u001b[1;32m--> 288\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;66;03m# null model with possible constant\u001b[39;00m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_fit((\u001b[38;5;241m0\u001b[39m, d, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, D, \u001b[38;5;241m0\u001b[39m, m)):\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:235\u001b[0m, in \u001b[0;36m_StepwiseFitWrapper._do_fit\u001b[1;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (order, seasonal_order, constant) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict:\n\u001b[0;32m    231\u001b[0m \n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# increment the number of fits\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 235\u001b[0m     fit, fit_time, new_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_arima\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# use the orders as a key to be hashed for\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# the dictionary (pointing to fit)\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_dict[(order, seasonal_order, constant)] \u001b[38;5;241m=\u001b[39m fit\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\_auto_solvers.py:508\u001b[0m, in \u001b[0;36m_fit_candidate_model\u001b[1;34m(y, X, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, **kwargs)\u001b[0m\n\u001b[0;32m    500\u001b[0m fit \u001b[38;5;241m=\u001b[39m ARIMA(order\u001b[38;5;241m=\u001b[39morder, seasonal_order\u001b[38;5;241m=\u001b[39mseasonal_order,\n\u001b[0;32m    501\u001b[0m             start_params\u001b[38;5;241m=\u001b[39mstart_params, trend\u001b[38;5;241m=\u001b[39mtrend, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    502\u001b[0m             maxiter\u001b[38;5;241m=\u001b[39mmaxiter, suppress_warnings\u001b[38;5;241m=\u001b[39msuppress_warnings,\n\u001b[0;32m    503\u001b[0m             out_of_sample_size\u001b[38;5;241m=\u001b[39mout_of_sample_size, scoring\u001b[38;5;241m=\u001b[39mscoring,\n\u001b[0;32m    504\u001b[0m             scoring_args\u001b[38;5;241m=\u001b[39mscoring_args,\n\u001b[0;32m    505\u001b[0m             with_intercept\u001b[38;5;241m=\u001b[39mwith_intercept, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 508\u001b[0m     fit\u001b[38;5;241m.\u001b[39mfit(y, X\u001b[38;5;241m=\u001b[39mX, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# for non-stationarity errors or singular matrices, return None\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (LinAlgError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m v:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\arima.py:603\u001b[0m, in \u001b[0;36mARIMA.fit\u001b[1;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[0;32m    600\u001b[0m         X \u001b[38;5;241m=\u001b[39m safe_indexing(X, \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_exog \u001b[38;5;241m-\u001b[39m cv))\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# Internal call\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(y, X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args)\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# now make a forecast if we're validating to compute the\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;66;03m# out-of-sample score\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m# get the predictions (use self.predict, which calls forecast\u001b[39;00m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;66;03m# from statsmodels internally)\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\arima.py:524\u001b[0m, in \u001b[0;36mARIMA._fit\u001b[1;34m(self, y, X, **fit_args)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    523\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 524\u001b[0m         fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m \u001b[43m_fit_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     fit, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marima_res_ \u001b[38;5;241m=\u001b[39m _fit_wrapper()\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pmdarima\\arima\\arima.py:510\u001b[0m, in \u001b[0;36mARIMA._fit.<locals>._fit_wrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m    507\u001b[0m _maxiter \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m\"\u001b[39m, _maxiter)\n\u001b[0;32m    509\u001b[0m disp \u001b[38;5;241m=\u001b[39m fit_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 510\u001b[0m fitted \u001b[38;5;241m=\u001b[39m arima\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    511\u001b[0m     start_params\u001b[38;5;241m=\u001b[39mstart_params,\n\u001b[0;32m    512\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    513\u001b[0m     maxiter\u001b[38;5;241m=\u001b[39m_maxiter,\n\u001b[0;32m    514\u001b[0m     disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_args,\n\u001b[0;32m    516\u001b[0m )\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arima, fitted\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:704\u001b[0m, in \u001b[0;36mMLEModel.fit\u001b[1;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m         flags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhessian_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m optim_hessian\n\u001b[0;32m    703\u001b[0m     fargs \u001b[38;5;241m=\u001b[39m (flags,)\n\u001b[1;32m--> 704\u001b[0m     mlefit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(MLEModel, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(start_params, method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    705\u001b[0m                                        fargs\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    706\u001b[0m                                        maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    707\u001b[0m                                        full_output\u001b[38;5;241m=\u001b[39mfull_output,\n\u001b[0;32m    708\u001b[0m                                        disp\u001b[38;5;241m=\u001b[39mdisp, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    709\u001b[0m                                        skip_hessian\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# Just return the fitted parameters if requested\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_params:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\base\\model.py:563\u001b[0m, in \u001b[0;36mLikelihoodModel.fit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_t\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    562\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer()\n\u001b[1;32m--> 563\u001b[0m xopt, retvals, optim_settings \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mhessian\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# Restore cov_type, cov_kwds and use_t\u001b[39;00m\n\u001b[0;32m    573\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\base\\optimizer.py:241\u001b[0m, in \u001b[0;36mOptimizer._fit\u001b[1;34m(self, objective, gradient, start_params, fargs, kwargs, hessian, method, maxiter, full_output, disp, callback, retall)\u001b[0m\n\u001b[0;32m    238\u001b[0m     fit_funcs\u001b[38;5;241m.\u001b[39mupdate(extra_fit_funcs)\n\u001b[0;32m    240\u001b[0m func \u001b[38;5;241m=\u001b[39m fit_funcs[method]\n\u001b[1;32m--> 241\u001b[0m xopt, retvals \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdisp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mretall\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mhess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhessian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m optim_settings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: method, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_params\u001b[39m\u001b[38;5;124m'\u001b[39m: start_params,\n\u001b[0;32m    247\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: maxiter, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_output\u001b[39m\u001b[38;5;124m'\u001b[39m: full_output,\n\u001b[0;32m    248\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfargs\u001b[39m\u001b[38;5;124m'\u001b[39m: fargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    249\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretall\u001b[39m\u001b[38;5;124m'\u001b[39m: retall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextra_fit_funcs\u001b[39m\u001b[38;5;124m\"\u001b[39m: extra_fit_funcs}\n\u001b[0;32m    250\u001b[0m optim_settings\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\base\\optimizer.py:651\u001b[0m, in \u001b[0;36m_fit_lbfgs\u001b[1;34m(f, score, start_params, fargs, kwargs, disp, maxiter, callback, retall, full_output, hess)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m approx_grad:\n\u001b[0;32m    649\u001b[0m     func \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m--> 651\u001b[0m retvals \u001b[38;5;241m=\u001b[39m optimize\u001b[38;5;241m.\u001b[39mfmin_l_bfgs_b(func, start_params, maxiter\u001b[38;5;241m=\u001b[39mmaxiter,\n\u001b[0;32m    652\u001b[0m                                  callback\u001b[38;5;241m=\u001b[39mcallback, args\u001b[38;5;241m=\u001b[39mfargs,\n\u001b[0;32m    653\u001b[0m                                  bounds\u001b[38;5;241m=\u001b[39mbounds, disp\u001b[38;5;241m=\u001b[39mdisp,\n\u001b[0;32m    654\u001b[0m                                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kwargs)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_output:\n\u001b[0;32m    657\u001b[0m     xopt, fopt, d \u001b[38;5;241m=\u001b[39m retvals\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:197\u001b[0m, in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# build options\u001b[39;00m\n\u001b[0;32m    186\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisp\u001b[39m\u001b[38;5;124m'\u001b[39m: disp,\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miprint\u001b[39m\u001b[38;5;124m'\u001b[39m: iprint,\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxcor\u001b[39m\u001b[38;5;124m'\u001b[39m: m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback\u001b[39m\u001b[38;5;124m'\u001b[39m: callback,\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxls\u001b[39m\u001b[38;5;124m'\u001b[39m: maxls}\n\u001b[1;32m--> 197\u001b[0m res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args\u001b[38;5;241m=\u001b[39margs, jac\u001b[38;5;241m=\u001b[39mjac, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m    198\u001b[0m                        \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m    199\u001b[0m d \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjac\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    200\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    201\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfuncalls\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnfev\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    202\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    203\u001b[0m      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarnflag\u001b[39m\u001b[38;5;124m'\u001b[39m: res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[0;32m    204\u001b[0m f \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:286\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:256\u001b[0m, in \u001b[0;36mScalarFunction._update_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated:\n\u001b[1;32m--> 256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_grad_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:173\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_grad\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m approx_derivative(fun_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, f0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf,\n\u001b[0;32m    174\u001b[0m                            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinite_diff_options)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:505\u001b[0m, in \u001b[0;36mapprox_derivative\u001b[1;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     use_one_sided \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m                             \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:576\u001b[0m, in \u001b[0;36m_dense_difference\u001b[1;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[0;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n\u001b[0;32m    575\u001b[0m     dx \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m-\u001b[39m x0[i]  \u001b[38;5;66;03m# Recompute dx as exactly representable number.\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m f0\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3-point\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_one_sided[i]:\n\u001b[0;32m    578\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x0 \u001b[38;5;241m+\u001b[39m h_vecs[i]\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_numdiff.py:456\u001b[0m, in \u001b[0;36mapprox_derivative.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun_wrapped\u001b[39m(x):\n\u001b[1;32m--> 456\u001b[0m     f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(fun(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`fun` return value has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmore than 1 dimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\base\\model.py:531\u001b[0m, in \u001b[0;36mLikelihoodModel.fit.<locals>.f\u001b[1;34m(params, *args)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m nobs\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:939\u001b[0m, in \u001b[0;36mMLEModel.loglike\u001b[1;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m complex_step:\n\u001b[0;32m    937\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minversion_method\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m INVERT_UNIVARIATE \u001b[38;5;241m|\u001b[39m SOLVE_LU\n\u001b[1;32m--> 939\u001b[0m loglike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssm\u001b[38;5;241m.\u001b[39mloglike(complex_step\u001b[38;5;241m=\u001b[39mcomplex_step, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# Koopman, Shephard, and Doornik recommend maximizing the average\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# likelihood to avoid scale issues, but the averaging is done\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;66;03m# automatically in the base model `fit` method\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loglike\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:983\u001b[0m, in \u001b[0;36mKalmanFilter.loglike\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;124;03mCalculate the loglikelihood associated with the statespace model.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;124;03m    The joint loglikelihood.\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    981\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    982\u001b[0m                   MEMORY_CONSERVE \u001b[38;5;241m^\u001b[39m MEMORY_NO_LIKELIHOOD)\n\u001b[1;32m--> 983\u001b[0m kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    984\u001b[0m loglikelihood_burn \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloglikelihood_burn\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    985\u001b[0m                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloglikelihood_burn)\n\u001b[0;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconserve_memory\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m&\u001b[39m MEMORY_NO_LIKELIHOOD):\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:895\u001b[0m, in \u001b[0;36mKalmanFilter._filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filter\u001b[39m(\u001b[38;5;28mself\u001b[39m, filter_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inversion_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    890\u001b[0m             stability_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, conserve_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    891\u001b[0m             filter_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, loglikelihood_burn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    892\u001b[0m             complex_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    893\u001b[0m     \u001b[38;5;66;03m# Initialize the filter\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     prefix, dtype, create_filter, create_statespace \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 895\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minversion_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstability_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconserve_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_timing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloglikelihood_burn\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    899\u001b[0m     )\n\u001b[0;32m    900\u001b[0m     kfilter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters[prefix]\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;66;03m# Initialize the state\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\kalman_filter.py:462\u001b[0m, in \u001b[0;36mKalmanFilter._initialize_filter\u001b[1;34m(self, filter_method, inversion_method, stability_method, conserve_memory, tolerance, filter_timing, loglikelihood_burn)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMust bind a dataset to the model before\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    459\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m filtering or smoothing.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# Initialize the representation matrices\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m prefix, dtype, create_statespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;66;03m# Determine if we need to (re-)create the filter\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;66;03m# (definitely need to recreate if we recreated the _statespace object)\u001b[39;00m\n\u001b[0;32m    466\u001b[0m create_filter \u001b[38;5;241m=\u001b[39m create_statespace \u001b[38;5;129;01mor\u001b[39;00m prefix \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kalman_filters\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\statsmodels\\tsa\\statespace\\representation.py:928\u001b[0m, in \u001b[0;36mRepresentation._initialize_representation\u001b[1;34m(self, prefix)\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 928\u001b[0m     new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m existing\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m new\u001b[38;5;241m.\u001b[39mshape:\n\u001b[0;32m    930\u001b[0m         existing[:] \u001b[38;5;241m=\u001b[39m new[:]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "train_fc_features = df[df['Year'] < min_year_test].copy()\n",
    "row_list = []\n",
    "\n",
    "for state in state_list:\n",
    "    row_dict = {}\n",
    "    # Subset the data for the current state\n",
    "    state_train_df = train_fc_features[train_fc_features['State'] == state]\n",
    "    state_train_df = state_train_df.sort_values(by='Year')\n",
    "    state_train_df = state_train_df.reset_index(drop=True)\n",
    "    \n",
    "    row_dict['State'] = state\n",
    "    row_dict['Year'] = list(range(2019, 2026))\n",
    "\n",
    "    for col in train_fc_features.columns[2:-7]:\n",
    "        # Fit an ARIMA model using the auto_arima function\n",
    "        model = auto_arima(state_train_df[col], seasonal=False, suppress_warnings=True)\n",
    "        print(f'Column: {col}, ARIMA Model: {model.order}')\n",
    "        forecast = model.predict(n_periods=7)\n",
    "        \n",
    "        row_dict[col] = forecast\n",
    "    \n",
    "    row_list.append(row_dict)\n",
    "\n",
    "# pred_fc_features_df = pd.DataFrame(row_list).explode(['Year'])\n",
    "# pred_fc_features_df = overview_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82130290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T13:17:48.100366Z",
     "start_time": "2023-04-17T13:17:48.046279Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns must have matching element counts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_fc_features_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTOT_POP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m pred_fc_features_df \u001b[38;5;241m=\u001b[39m pred_fc_features_df\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m pred_fc_features_df\n",
      "File \u001b[1;32m~\\.conda\\envs\\ba\\lib\\site-packages\\pandas\\core\\frame.py:9038\u001b[0m, in \u001b[0;36mDataFrame.explode\u001b[1;34m(self, column, ignore_index)\u001b[0m\n\u001b[0;32m   9036\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m   9037\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(counts0 \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m[c]\u001b[38;5;241m.\u001b[39mapply(mylen)):\n\u001b[1;32m-> 9038\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns must have matching element counts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9039\u001b[0m     result \u001b[38;5;241m=\u001b[39m DataFrame({c: df[c]\u001b[38;5;241m.\u001b[39mexplode() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m columns})\n\u001b[0;32m   9040\u001b[0m result \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(result)\n",
      "\u001b[1;31mValueError\u001b[0m: columns must have matching element counts"
     ]
    }
   ],
   "source": [
    "pred_fc_features_df = pd.DataFrame(row_list).explode(['Year', 'Tax', 'TOT_POP'])\n",
    "pred_fc_features_df = pred_fc_features_df.reset_index(drop=True)\n",
    "pred_fc_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05d940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T12:43:27.043570Z",
     "start_time": "2023-04-17T12:43:27.035026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f49fa93",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- Make the prediction for each of the states and cancers for the test dataset (Not validation) to report the accuracy for the data which haven't been seen \n",
    "\n",
    "- Compare the results with baseline model (ARIMA)\n",
    "\n",
    "- Predict the future data which we don't have any features for. This probably needs to predict the features like air pollution and demopraghic data for the future.\n",
    "\n",
    "- Use SHAP to find the features which have the most impact in each state, for each cancer (find the interesting things like if for most of the states and cancers the important features are the same or for instance, for some of them, some features are more important)\n",
    "\n",
    "- Have a map of the states in danger (By having a cut-off for 3 situations like Green, Yellow, Red)\n",
    "- Text Analysis on News\n",
    "- EDA on features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
